---
title: "Mathematical Statistics"
author: "林嘉文"
date: "2017年8月26日"
output: html_document
---
首先我们明确我们所学的是参数统计，与之相对应的是非参数统计。它们都会涉及到*参数估计*和*假定检验*，这也是数理统计要做的两件最主要的事情。参数统计与非参数统计的区别就在于，参数统计对于随机变量的分布是有假设的，而非参数统计则相对来说缺少对于分布的假设,相对更robust。

但是我们肯定想问，到底我们是在干什么呢？统计所在做的分为描述性统计和推断性统计(describetive statistics and inference statistics),我们现在说的是推断性统计到底在做什么。推断性统计其实都是为了研究“某个事情的规律”，这里的“某个事情”泛指某个随机变量，“规律”指的就是随机变量的分布。这世间很多东西可以简化为随机变量的各种取值，因此我们最想知道的就是这个随机变量的分布，而推断性统计就是为了将这个随机变量的分布找出来。对于随机变量而言，得到分布就得到了一切。

但是我们永远无法确切知道分布到底是什么样子的，因此我们只能*估计*，估计完了之后还要*检定*这个估计是否正确。



#Chapter 5 Parameter Estimation

* 样本必须iid，并具有代表性。
* 从大量数据中得出分布，有两种方法，一种是参数估计方法，一种是非参数估计方法，分别对应于参数统计和非参数统计。

##参数估计基本介绍

参数估计方法就是我们假设随机变量服从某个分布$f_{X}(x)=f(x,\theta)$,其中$f_{X}()$是已知函数而参数$\theta$是未知的，从而我们的任务从估计其分布变成估计参数，这里的$\theta$是一个概括，它可以是一个或者多个未知参数。

> 如果$f_{X}(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}$,则$\theta=(\mu,\sigma)$  
> 从这里我们就要记住我们现在的任务是估计一个*固定的*、*未知的*值。

##Statistics

定义：$X^{n}=(X_{1},X_{2},X_{3},...,X_{n})$是从总体中取出的n个iid随机变量。$T(X^{n})=T(X_{1},X_{2},X_{3},...,X_{n})$则称为一个*统计量(statistic)*

> 统计量也是一个随机变量，因为它实际上是对$X^{n}$加了一个法则。因此统计量也具有概率分布，也有期望、方差这些性质。  
> 统计量中不能出现未知参数，不然不叫统计量。统计量的分布有可能已知有可能未知。与之相对应的一个东西叫做*枢轴量*，枢轴量是含有未知参数的随机变量，但是它的分布是已知的。  
> 为什么要弄这么一个统计量呢？在我看来，其实统计量就是用来估计参数的。它也符合我们的一个逻辑：我们只拥有许多数据，这些数据是iid样本$X^{n}$的一次（或多次）取值，那么我们构造的统计量也能得到相应的取值，如果这些统计量被证明是一些参数的好的估计，那么我们就可以用它们来估计参数了。  
> eg:$\bar{X_{n}}=\frac{\sum_{i=1}^{n}X_{i}}{n}$,$S_{n}^{2}=\frac{\sum_{i=1}^{n}(X_{i}-\bar{X_{n}})^{2}}{n-1}$,它们分别是样本均值和样本方差，但是实际上它们就是统计量。它们是由iii样本$X^{n}$构成的函数，它们是随机变量。


**样本均值$\bar{X_{n}}$**

样本均值，就是对样本取平均。
$$\bar{X_{n}}=\frac{1}{n}\sum\limits_{i=1}^{n}X_{i}$$
那么我们就会自然想知道它的期望、方差以及分布是什么，
$$E(\bar{X_{n}})=E(\frac{1}{n}\sum\limits_{i=1}^{n}X_{i})=\frac{1}{n}\sum\limits_{i=1}^{n}E(X_{i})=\frac{1}{n}\sum\limits_{i=1}^{n}\mu=\mu$$

> 因为$X_{i}$是iid的，所以得到这个结果。可以看到样本均值的期望就是$X_{i}$的期望$\mu$。因此我们把样本均值称为是总体均值$\mu$的无偏估计。

$$Var(\bar{X_{n}})=Var(\frac{1}{n}\sum\limits_{i=1}^{n}X_{i})=\frac{1}{n^{2}}Var(\sum\limits_{i=1}^{n}X_{i})=\frac{1}{n^{2}}\sum\limits_{i=1}^{n}Var(X_{i})=\frac{\sigma^{2}}{n}$$

> 求解过程中，因为$X_{i}$是独立同分布的，因此所有的协方差均为0。可以看到最后样本均值的方差和$X_{i}$的方差不同，它衡量的是$\bar{X_{n}}$这一随机变量的波动程度。  
> 当n越大，$Var(\bar{X_{n}})$越小。当$n\rightarrow\infty$，$Var(\bar{X_{n}})\rightarrow 0$,换句话说就是当n趋向无穷时，样本均值就是总体均值。


Theorem:suppose $X^{n}=(X_{1},X_{2},...X_{n})$是iid正态分布的随机样本，均值为$\mu$，方差为$\sigma^{2}$，那么就有
$$\bar{X_{n}}\sim N(\mu,\frac{\sigma^{2}}{n})$$

> 这个其实都不能算是一个theorem，因为这个实际上就是我们在概率论中说的sum of independent R.V.的结论的使用。

Central Limit Theorem:$X^{n}=(X_{1},X_{x},...,X_{n})$是iid的随机样本，均值为$\mu$，方差为$\sigma^{2}$，$\bar{X_{n}}=\frac{1}{b}\sum\limits_{i=1}^{n}X_{i}$,则
$$Z_{n}=\frac{\bar{X_{n}}-\mu}{\frac{\sigma}{\sqrt{n}}}\xrightarrow{d}N(0,1)$$

> 中心极限定理并不要求$X_{i}$的任何分布信息，只需要n足够大。

**样本方差$S_{n}^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}(X_{i}-\bar{X_{n}})^{2}$**

我们的第一反应其实是仿照样本均值，分母似乎是n而不是(n-1)，但是我们可以证明分母是(n-1)才能使其是总体方差的无偏估计。

$$S_{n}^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}(X_{i}-\bar{X_{n}})^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}[(X_{i}-\mu)-(\bar{X_{n}}-\mu)]^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}[(X_{i}-\mu)^{2}-2(X_{i}-\mu)(\bar{X_{n}}-\mu)+(\bar{X_{n}}-\mu)^{2}]$$
$$\Rightarrow S_{n}^{2}=\frac{1}{n-1}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-2\sum\limits_{i=1}^{n}(X_{i}-\mu)(\bar{X_{n}}-\mu)+\sum\limits_{i=1}^{n}(\bar{X_{n}}-\mu)^{2}]=\frac{1}{n-1}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-2(\bar{X_{n}}-\mu)\sum\limits_{i=1}^{n}(X_{i}-\mu)+n\cdot(\bar{X_{n}}-\mu)^{2}]$$
$$\Rightarrow S_{n}^{2}=\frac{1}{n-1}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-2(\bar{X_{n}}-\mu)(\sum\limits_{i=1}^{n}X_{i}-n\cdot\mu)+n\cdot(\bar{X_{n}}-\mu)^{2}]=\frac{1}{n-1}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-2(\bar{X_{n}}-\mu)\cdot n\cdot(\bar{X_{n}}-\mu)+n\cdot(\bar{X_{n}}-\mu)^{2}]$$
$$\Rightarrow S_{n}^{2}=\frac{1}{n-1}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-n\cdot(\bar{X_{n}}-\mu)^{2}]$$
$$\therefore E(S_{n}^{2})=\frac{1}{n-1}E[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-n\cdot(\bar{X_{n}}-\mu)^{2}]=\frac{1}{n-1}(n\cdot\sigma^{2}-n\cdot\frac{\sigma^{2}}{n})=\sigma^{2}$$

> 显然我们可以看到，如果分母不是(n-1)，那么样本方差的期望就不是$\sigma^{2}$啦！

为了推出样本方差的方差和分布，我们需要证明：
$$\textrm{Suppose }X^{n}\textrm{ is a iid }N(\mu,\sigma^{2})\textrm{ random sample.Then for any n>1},S_{n}^{2}\,\,and\,\,\bar{X_{n}}\textrm{ are mutually independent.That is }S_{n}^{2}\bot\bar{X_{n}}$$

> 这个我们就不详细证了，我们说一下大致的思路。等价于要证明$(X_{1}-\bar{X_{n}},X_{2}-\bar{X_{n}},...,X_{n}-\bar{X_{n}})\bot X_{n}$,则我们进行一次换元，以简化字符，然后通过$f_{X,Y}(x,y)=h(x)\cdot g(y)$这个推论来证明独立。  
> 我们会用到雅可比矩阵的知识，因为我们需要在换元之后得到新的联合分布。  
> 这个理论要求X必须来自正态分布，在证明中要用到。所以一定要注意这个前提。

Theorem:$\frac{(n-1)S_{n}^{2}}{\sigma^{2}}\sim \chi_{n-1}^{2}$

需要说明的是，首先要求X来自一个正态分布，那么这个随机样本的样本方差有这样一个结论，其中$X_{n-1}^{2}$是自由度为(n-1)的卡方分布。

$$\frac{(n-1)S_{n}^{2}}{\sigma^{2}}=\sum\limits_{i=1}^{n}\frac{(X_{i}-\bar{X_{n}})^{2}}{\sigma^{2}}=\sum\limits_{i=1}^{n}\frac{[(X_{i}-\mu)-(\bar{X_{n}}-\mu)]^{2}}{\sigma^{2}}=\frac{1}{\sigma^{2}}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-n\cdot(\bar{X_{n}}-\mu)^{2}]$$
$$\Rightarrow \frac{(n-1)S_{n}^{2}}{\sigma^{2}}=\sum\limits_{i=1}^{n}(\frac{X_{i}-\mu}{\sigma})^{2}-n\cdot (\frac{\bar{X_{n}}-\mu}{\sigma})^{2}=\sum\limits_{i=1}^{n}(\frac{X_{i}-\mu}{\sigma})^{2}-(\frac{\bar{X_{n}}-\mu}{\frac{\sigma}{\sqrt{n}}})^{2}$$
$$\Rightarrow \textrm{令 }U=\sum\limits_{i=1}^{n}(\frac{X_{i}-\mu}{\sigma})^{2},Z=(\frac{\bar{X_{n}}-\mu}{\frac{\sigma}{\sqrt{n}}})^{2},W=\frac{(n-1)S_{n}^{2}}{\sigma^{2}}$$
$$\therefore U=Z+W$$
$$M_{U}(t)=M_{Z+W}(t)=E[e^{(z+w)t}]=E(e^{zt+wt})=\int\int e^{zt+wt}f_{Z,W}(z,w)dzdw=\int e^{zt}f(z)dz\int e^{wt}f(w)dw=(1-2t)^{-\frac{1}{2}}M_{W}(t)$$
$$\because M_{U}(t)=(1-2t)^{-\frac{n}{2}}\quad\therefore M_{W}(t)=(1-2t)^{-\frac{n-1}{2}}$$
$$\therefore \frac{(n-1)S_{n}^{2}}{\sigma^{2}}\sim \chi_{n-1}^{2}$$

> 在我们使用矩母函数的时候，我们把联合分布拆开就用到了样本均值和样本方差独立的条件。  
> $If\,\,X\sim N(0,1),then\,\,X^{2}\sim \chi_{1}^{2}$  
> $If\,\,X_{i}\sim N(0,1),iid,then\,\,\sum_{i=1}^{n}X_{i}^{2}\sim \chi_{n}^{2}$  
> 为什么这里自由度是(n-1)呢，其实也是有讲究的。假设有$W_{n}^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}$,则有$\frac{(n-1)W_{n}^{2}}{\sigma^{2}}=\sum\limits_{i=1}^{n}(\frac{X_{i}-\mu}{\sigma})^{2}\sim \chi_{n}^{2}$。但是因为我们在$S_{n}^{2}$里面把均值换成了样本均值，就会丢失了一个信息，所以自由度减少1.

有了分布之后，方差就很好计算了。因为

$$E(\chi_{n-1}^{2})=n-1,Var(\chi_{n-1}^{2})=2(n-1)$$
$$\Rightarrow Var(\frac{(n-1)S_{n}^{2}}{\sigma^{2}})=2(n-1)$$
$$\Rightarrow \frac{(n-1)^{2}}{\sigma^{4}}Var(S_{n}^{2})=2(n-1)$$
$$\therefore Var(S_{n}^{2})=\frac{2\sigma^{4}}{n-1}$$


##Two classical estimation methods

前面我们讲的样本均值和样本方差实际上也可以作为均值和方差的估计量，但是它们是我们从直觉中找到的统计量，而不是通过某种方法找到的。现在我们要介绍两种最主要的参数估计方法。

**Maximum likelihood estimation**

*本质：观察到已经发生的事件，求得使这件事发生概率最大的参数的值。*

> 这种方法有一个很本质的想法，比如说一个池塘有A,B两种鱼，你随便捞10条鱼，其中8条是A，2条是B，从而你估计池塘中80%是A鱼;又比如说拿一枚硬币投掷30次，结果是20次为字朝上，10次花朝上，从而你估计字朝上的概率是$\frac{2}{3}$。  
> 概率论是已知参数求概率，而数理统计是由观察到的数据估计参数。

The procedure to find a maximum likelihood estimator for $\theta$

1. 得到$L(\theta)$,$L(\theta)=\prod\limits_{i=1}^{n}f_{Y}(yi,\theta)$.
2. 对$L(\theta)$取对数,$\rho(\theta)=ln(L(\theta))$（方便运算，尤其对于指数类的概率分布函数。并且ln是单调递增的，不会影响到$L(\theta)$的极值点）
3. 解等式$\frac{d\rho(\theta)}{d\theta}=0$，求得极值点
4. 验证二阶导是否小于0，保证极值点为极大值点。（这一步一般来说不需要）

> $L(\theta)被称为似然函数(likelihood function),要得到这个东西，前提就是我们已知Y的分布，所以最大似然估计很显然就是参数估计的方法。$  
> 实际上我们在求的东西是，$\hat{\theta}=arg\,max_{\theta}L(\theta|Y_{1},Y_{2},...Y_{n})$。在随机样本没有取值之前，这个表达式是一个随机变量，也就是一个estimator，但是当随机样本取值之后，这个estimator也会取一个值，也就是estimate。

> eg1:我们以掷硬币为例子，我们想要估计的很显然就是伯努利分布中的那个p。  
> 对于伯努利分布，$f_{X}(x)=p^{x}(1-p)^{1-x},x\in\{0,1\}$  
> $\Rightarrow L(p)=f_{X}(x_{1})f_{X}(x_{1})\cdots f_{X}(x_{n})=p^{\sum\limits_{i=1}^{n}x_{i}}(1-p)^{n-\sum\limits_{i=1}^{n}x_{i}}$  
> $\Rightarrow\rho(p)=ln(L(p))=\sum\limits_{i=1}^{n}x_{i}ln(p)+(n-\sum\limits_{i=1}^{n}x_{i})ln(1-p)$  
> $\Rightarrow\frac{d\rho(p)}{dp}=\sum\limits_{i=1}^{n}x_{i}\frac{1}{p}-(n-\sum\limits_{i=1}^{n}x_{i})\frac{1}{1-p}=\frac{(1-p)\sum\limits_{i=1}^{n}x_{i}-p(n-\sum\limits_{i=1}^{n}x_{i})}{p(1-p)}=0$  
> $\therefore\quad \hat{p}=\frac{1}{n}\sum\limits_{i=1}^{n}x_{i}$  
> 这个就是p的估计量，它首先是一个随机变量，其实就是样本均值。当我们进行实验得到数据之后，就可以得到一个具体的估计值。

> eg2:当未知参数不止一个的时候，例如有两个参数则要对两个参数求偏导并联立求解。$X_{i}\sim N(\mu,\sigma),X^{n}=(X_{1},X_{2},...,X_{n})$。求均值和方差的最大似然估计量。  
> $f_{X}(X)=\frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-frac{(x-\mu)^{2}}{2\sigma^{2}}}$  
> $\Rightarrow L(\mu,\sigma^{2})=\prod\limits_{i=1}^{n}f_{X}(x_{i},\mu,\sigma^{2})=\frac{1}{(2\pi\sigma^{2})^{\frac{n}{2}}}e^{-\frac{\sum\limits_{i=1}^{n}(x_{i}-\mu)^{2}}{2\sigma^{2}}}$  
> $\Rightarrow \rho(\mu,\sigma^{2})=ln(L(\mu,\sigma^{2}))=-\frac{n}{2}ln(2\pi\sigma^{2})-\frac{\sum\limits_{i=1}^{n}(x_{i}-\mu)^{2}}{2\sigma^{2}}$  

$$\left\{
\begin{array}{1}
\frac{d\rho(\mu,\sigma^{2})}{d\mu}=\frac{\sum\limits_{i=1}^{n}(x_{i}-\mu)}{\sigma^{2}}=0\\ \frac{d\rho(\mu,\sigma^{2})}{d\sigma^{2}}=-\frac{n}{2}\cdot\frac{1}{\sigma^{2}}+\frac{\sum\limits_{i=1}^{n}(x_{i}-\mu)^{2}}{2}\cdot\frac{1}{\sigma^{4}}=0\\
\end{array}
\right.$$

$$
\left\{
\begin{array}{1}
\hat{\mu}=\bar{X_{n}}\\
\hat{\sigma^{2}}=\frac{1}{n}\sum\limits_{i=1}^{n}(X_{i}-\bar{X_{n}})^{2}\\
\end{array}
\right.$$  

> P.S.一定要注意，如果是对$\sigma^{2}$进行估计，那么求偏导的时候就要把整个当做一个整体。  
> 可以看到，用MLE来估计的方差的分母是n而不是样本方差中的(n-1)。所以显然它是一个有偏的估计量。

当无法使用求导来求极大值时，就应该使用其他方法来求。

> eg3:$f_{Y}(y)=e^{-(y-\theta)},y\geq\theta,\theta>0,Y^{n}=(Y_{1},Y_{2},...,Y_{n}).$  
> $L(\theta)=\prod\limits_{i=1}^{n}e^{-(y_{i}-\theta)}$  
> $\Rightarrow \rho(\theta)=ln(L(\theta))=\sum\limits_{i=1}^{n}\theta-y_{i}$  
> $\frac{d\rho(\theta)}{d\theta}=n>0$  
> 显然这里就没法说令其等于0，因为这个是一个递增函数没有极值点。但是因为它是递增的，如果我们在其定义域中取最大值就可以使函数最大化了。    
> $\because \theta\leq y,\quad \therefore \theta\leq min(y_{i})=y_{(1)}$  
> $\therefore \hat{\theta}=y_{(1)}$


**Moments Estimation**

首先我们要回忆一下关于矩的一些知识：

$$E(X^{k})=
\left\{
\begin{array}{11}
\sum_{x}x^{k}f(x) & discrete R.V.\\
\int x^{k}f(x)dx & continuous R.V.\\
\end{array}
\right.$$

矩估计的使用方法：

1. 首先，你先要判断一共要估计多少个未知参数。如果呀估计s个未知参数，就要用到s阶矩。分别计算s阶矩的表达式，它们由着s个未知参数的代数式表示。
2. 我们所要做的仅仅是用样本矩去替代总体矩,作为总体矩的估计，然后反解出各个参数的估计表达式即可（解方程组）

*j阶样本矩*：
$$\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i}^{j}$$

> eg1:Suppose that $Y^{n}=(Y_{1},Y_{2},...,Y_{n})$ is a random sample of size n from a normal distribution with mean $\mu$ and variance $\sigma^{2}$.Estimate these two parameters.  
> $\mu=E(Y),\sigma^{2}=E(Y^{2})-(E(Y))^{2}$  
> $\Rightarrow \hat{\mu}=\hat{E(Y)}=\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i},\hat{\sigma^{2}}=\hat{E(Y^{2})}-(\hat{E(Y)})^{2}=\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i}^{2}-(\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i})^{2}$  
> 这就是矩估计量

> eg2:Suppose that $Y^{n}=(Y_{1},Y_{2},...,Y_{n})$ is a random sample of size n from a general gamma distribution with the pdf $f_{Y}(y,\alpha,\beta)=\frac{1}{\tau(\alpha)\beta^{\alpha}}y^{\alpha-1}e^{-\frac{y}{\beta}},for\,\,y>0$,where $\alpha,\beta>0$ and $\tau(\alpha)=\int_{0}^{\infty}t^{\alpha-1}e^{-t}dt$.Estimate $\alpha,\beta$  
> $E(Y)=\alpha\beta,Var(Y)=\alpha\beta^{2}$  
> $\Rightarrow \beta=\frac{E(Y^{2})-(E(Y))^{2}}{E(Y)},\alpha=\frac{(E(Y))^{2}}{E(Y^{2})-(E(Y))^{2}}$  
> $\therefore \hat{\beta}=\frac{\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i}^{2}-(\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i})^{2}}{\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i}},\hat{\alpha}=\frac{(\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i})^{2}}{\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i}^{2}-(\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i})^{2}}$

*所以你会发现MME非常方便，因为它的过程非常简单不想MLE那样需要求极值之类的，同时MME没有直接用到分布的信息。但是我们可以看到，因为它的简便性，它的精确度就没有MLE那么高，毕竟它只使用了矩的信息，而没有使用整个分布的信息。*



##Interval Estimation

之前我们所做的都是point estimation(点估计),也就是说我们每次我们进行一次估计，因为估计量是一个随机变量，它就会得到一次取值，是一个点。但是这样就存在一个问题：好比说有一个无偏的估计量，它的期望就是这个未知的参数值，这时候如果只进行一次观察得到估计量的一个实现值，我们就无法知道这个实现值到底离它的均值是近还是远，尽管按理来说大部分的实现值会在期望附近出现。那我们可能又会问了，那就多观察几次呗？但是一般来说我们只会对随机样本进行一次取值。

To this end,we usually construct a confidence interval to quantify the amount of uncertainty in an estimator.By looking at the width of a confidence interval,we can get a good sense of the estimators precision.

> 说白了，区间估计从估计的角度来说是对点估计的改进。它的改进在于减少了点估计的不确定性，这个不确定性就体现在我刚刚说的在一次取值中无法知道它离期望是远是近。但是用区间估计的话，就会控制住这个不确定性。

Given a confidence level $1-\alpha\in[0,1]$,we have two statistics
$$\textrm{lower bound: }L(X_{1},X_{2},...,X_{n})\textrm{ and upper bound: }U(X_{1},X_{2},...,X_{n})$$
such that
$$P_{\theta_{0}}\{L(X_{1},X_{2},...,X_{n})\leq\theta_{0}\leq U(X_{1},X_{2},...,X_{n})\}=1-\alpha$$
We say that $[L(X_{1},X_{2},...,X_{n}),U(X_{1},X_{2},...,X_{n})]$ is the confidence interval of the unknown parameter $\theta_{0}$ with confidence level $1-\alpha$

> 注意了，L和U其实都是随机变量，都是统计量。相较于点估计只用了一个随机变量，现在我们用两个随机变量去框住一个范围。

问题在于我们如何能够构造出confidence interval呢？我们必须回到自信区间的定义去寻找方法。可以看到我们只要能够实现这样的一个概率等式，那么我们就算找到了L和U。关键点有两个：

1. 区间估计是点估计的升级改进，所以会和点估计有一定的联系
2. 枢轴量

> eg1:$X_{i}\sim N(\mu,\sigma^{2})$,其中方差已知，我们想要求得均值的区间估计。那么我们首先想到的当然是  
> $$\frac{\bar{X_{n]}}-\mu}{\frac{\sigma}{\sqrt{n}}}\sim N(0,1)$$  
> $$\Rightarrow P(-Z_{\frac{\alpha}{2}}\leq\frac{\bar{X_{n}}-\mu}{\frac{\sigma}{\sqrt{n}}}\leq Z_{\frac{\alpha}{2}})=1-\alpha$$  
> $$\Rightarrow P(\bar{X_{n}}-Z_{\frac{\alpha}{2}}\cdot\frac{\sigma}{\sqrt{n}}\leq\mu\leq\bar{X_{n}}+Z_{\frac{\alpha}{2}}\cdot\frac{\sigma}{\sqrt{n}})=1-\alpha$$  
> $$\therefore [\bar{X_{n}}-Z_{\frac{\alpha}{2}}\cdot\frac{\sigma}{\sqrt{n}},\bar{X_{n}}+Z_{\frac{\alpha}{2}}\cdot\frac{\sigma}{\sqrt{n}}]\textrm{就是我们要找的自信度为}(1-\alpha)\textrm{的自信区间}$$  
> 可以看到，首先我们会先找均值的点估计量，但是最关键的是概率等式中的那个枢轴量，它含有未知参数$\mu$，但是我们知道它的分布，知道它的分布就可以求概率了！！！然后再把未知参数放在中间就好了。

> eg2:如果X不服从正态分布且方差已知，我们仍然想估计它的均值。那么由中心极限定理我们还是有  
> $$\frac{\bar{X_{n}}-\mu}{\frac{\sigma}{\sqrt{n}}}\xrightarrow{d}N(0,1)$$  
> 后面的过程和第一个例子是相同的，关键点还是我们用CLT得到了一个类似于枢轴量的东西。也就是我们必须得到一个已知的分布。

> eg3:在前两个例子中，方差总是已知的。如果方差未知我们可以用样本方差替代总体方差。当X是正态分布时，那个枢轴量将服从T分布；当X是未知分布时，通过中心极限定理以及Slutsky's Theorem可以得到那个枢轴量仍然依概率收敛于标准正态分布。

> eg4:Let $X\sim Bin(n,p)$.We are interested in the confidence interval of p.Note that $X=\sum\limits_{i=1}^{n}Y_{i}$ with $Y_{i}$ iid from Bernoulli(p).  
> $$\textrm{由CLT }，\frac{\frac{X}{n}-p}{\sqrt{\frac{p(1-p)}{n}}}\xrightarrow{d}N(0,1)$$  
> $$\Rightarrow P(-Z_{\frac{\alpha}{2}}\leq\frac{\frac{X}{N}-p}{\sqrt{\frac{p(1-p)}{n}}}\leq Z_{\frac{\alpha}{2}})=1-\alpha$$  
> 这时候你发现没有办法把p单独分离出来，无法得到自信区间的定义式。但是我们可以通过Slutsky's Theorem再构造一个依概率收敛于标准正态分布的枢轴量。具体就不展开了。


最后，我们还要说一下对于区间估计的理解。所有的理解都是基于自信区间的定义式展开的，因为它是一个概率等式，那么这个自信度$(1-\alpha)$的意思就是概率的意思。比如说自信度为95%，那意思就是如果我*能够*重复观察10000次，那么其中9500次均值会落在这个区间内，如果我*能够*重复观察100000次，那么其中95000次均值会落在这个区间内。但是，还是之前的那句话，*一般来说我们只进行一次观察*，对于这一次观察这个均值到底落不落进这一次的实现范围，只有两种情况：要么落进去，要么不落进去。而这个自信度越高，说明落进去的概率越大，那么对应于某一次来说我们*更加相信*它是落进去的。至于到底落进去没有，只有上帝知道了。


##Properties of Estimators

之所以我们想要了解估计量的性质，是因为我们想知道：哪一个估计量更好？因为估计量实际上就是统计量，因此它是一个随机变量，也就会有期望、方差、分布这些性质，这也是我们用来判断的标准。

**Unbiasedness**

Definition:Suppose $Y^{n}=(Y_{1},Y_{2},...,Y_{n})$ is a random sample with pdf $f_{Y}(y,\theta)$,$\theta$ is an unknown parameter.Then $\hat{\theta}=h(Y_{1},Y_{2},...,Y_{n})$ is called unbiased estimator if
$$E(\hat{\theta})=\theta$$
and the bias of $\hat{\theta}$ is defined by
$$Bias(\hat{\theta})=E(\hat{\theta})-\theta$$

> eg:$Y_{1},Y_{2},...,Y_{n}\sim f_{Y}(y,\theta)=\frac{2y}{\theta^{2}},0\leq y\leq\theta$.Give the MLE and MME of $\theta$ and distinguish their unbiasedness.  
> 我们直接给出两种估计量，  
> $$\hat{\theta_{MLE}}=Y_{Max}=Y_{(n)},\hat{\theta_{MME}}=\frac{3}{2}\cdot\bar{Y_{n}}$$  
> $$E(\hat{\theta_{MME}})=\frac{3}{2n}E(\sum\limits_{i=1}^{n}Y_{i})=\frac{3}{2}E(Y_{i}),E(Y_{i})=\int_{0}^{\theta}Y\cdot f_{Y}(y,\theta)dy=\frac{2}{3}\theta$$  
> $$\therefore E(\hat{\theta_{MME}})=\theta\quad \textrm{MME为无偏估计量}$$
> $$E(\hat{\theta_{MLE}})=E(Y_{(n)})=\frac{2n}{2n+1}\theta$$  
> $$\therefore \textrm{MLE是有偏估计量且 } Bias(\hat{\theta_{MLE}})=E(\hat(\theta_{MLE}))-\theta=-\frac{1}{2n+1}\theta$$

Find an unbiased estimator for some parameter

方法：一般来说我们一开始找到的估计量它的期望会带有这个未知参数的一部分或者除了这个未知参数以外还多了一些东西。如果一开始找到的这个估计量的期望就是未知参数，那就刚刚好，但大多数之后是有偏的——可能是多了一个系数，也可能是多了一些代数式子。那么我们就反向处理即可。

> eg1:$X^{n}$ is an iid random sample from some population with $\mu$ and $\sigma$.Find an unbiased estimator for $Var_{\theta}(\bar{X_{n}})$  
> 首先我们知道我们要估的是$\frac{\sigma^{2}}{n}$，那么我们就要找一个估计量它的期望里面能包含方差$\sigma^{2}$，所以就找到了样本方差。但是还少一个系数，所以就有  
> $$E(\frac{1}{n}S_{n}^{2})=\frac{1}{n}\sigma^{2}=\frac{\sigma^{2}}{n}$$

> eg2:$X^{n}$ is an iid random sample from some population with $\mu$ and $\sigma$.Find an unbiased estimator for $\mu^{2}$  
> 我们知道样本均值的期望是$\mu$，所以我们想到样本均值的平方可能可行。  
> $E(\bar{X_{n}}^{2})=Var(\bar{X_{n}})+[E(\bar{X_{n}})]^{2}=\frac{\sigma^{2}}{n}+\mu^{2}$,多了一个部分我们就反向处理！  
> $\because E(\frac{1}{n}S_{n}^{2})=\frac{\sigma^{2}}{n}\quad\therefore E(\bar{X_{n}}^{2}-\frac{1}{n}S_{n}^{2})=\mu^{2}$  
> $\bar{X_{n}}^{2}-\frac{1}{n}S_{n}^{2}$就是我们找的无偏估计量


**Efficiency**

对于一个未知参数，它可以有不止一个统计量，那么它当然也有可能有不止一个无偏统计量，那么对于多个无偏统计量，哪一个更好呢？

我们在考察估计量的时候，除了看其无偏性以外，还会看它的精确度(precision)。可以这样想，无偏就是这个估计量取很多次值但是它们平均来说会不会和真实的参数相等；精确度则是说这个估计量会不会大范围波动。

Definition:Relative Efficiency

Let $\hat\theta_{1}$ and $\hat\theta_{2}$ be two unbiased estimators for $\theta$.If
$$Var(\hat\theta_{2})<Var(\hat\theta_{1})$$
we say that $\hat\theta_{2}$ is more efficient than $\hat\theta_{1}$,also the relative efficiency of $\hat\theta_{2}$ with respect to $\hat\theta_{1}$ is the ratio
$$\frac{Var(\hat\theta_{1})}{Var(\hat\theta_{2})}$$

> 因为这个是2对于1的有效性，如果2对于1更加有效说明2的方差更小，所以这个ratio中分子是1的方差，分母是2的方差。

> 这里要说明一下。$Var\rightarrow\textrm{precision 准度/准确度}$，$Bias\rightarrow\textrm{accuracy 精度/精确度}$


**Mean Squared Error**

我们从unbiasedness开始比较两个estimator的好坏，然后在都是无偏的情况下时我们用efficiency来进行比较。那么进一步我们就想问一个问题：*如果一个估计量是有偏但方差小一些，另一个是无偏但方差大一些，这两个估计量哪个更优？*

$$MSE=E[(\hat\theta-\theta)^{2}]$$

> MSE的想法是：我们使用$\hat\theta$的目的是为了顾及$\theta$，所以两者当然越接近越好，那么就转变为我们怎么去度量这个接近程度。如果这样想的话，好像$E(\hat\theta-\theta)$也可以，但是问题在于它度量的是difference,它是可以正负相抵消的！因此我们进行改进就有了考虑distance的两种衡量方法  
> $$E(|\hat\theta-\theta|)\quad\textrm{or}\quad E[(\hat\theta-\theta)^{2}]$$  
> 现在我们只考虑使用平方的方法，因为从数理角度看，平方比绝对值更好处理。  
> 还要注意的一点是，这里的$\theta$并不是天然就是$\hat\theta$的期望啊!

$$MSE(\hat\theta)=E[(\hat\theta-\theta)^{2}]=E[(\hat\theta-E(\hat\theta)+E(\hat\theta)-\theta)^{2}]=E[(\hat\theta-E(\hat\theta))^{2}]+2E[(\hat\theta-E(\hat\theta))(E(\hat\theta)-\theta)]+E[(E(\hat\theta)-\theta)^{2}]$$
$$\Rightarrow MSE(\hat\theta)=Var(\hat\theta)+2(E(\hat\theta)-\theta)E[\hat\theta-E(\hat\theta)]+(E(\hat\theta)-\theta)^{2}$$
$$\therefore MSE(\hat\theta)=Var(\hat\theta)+[Bias(\hat\theta)]^{2}$$

> 可以发现，我们找到了连接*无偏性*和*有效性*去判断估计量好坏的一种方法，并且有效性其实就是当偏差为0的特例。


**Best Unbiased Estimators**

在有了MSE这个判断标准之后，如果我们想找一系列估计量中最好的那个，只要找到那个有最小均方误差的估计量即可。但是我们几乎无法一一比较每一个估计量尤其是当估计量很多的时候，因此我们做出必要的简化。我们去寻找*最优无偏估计量*

在一系列的$\hat\theta$中，称$\hat\theta_{\star}$为minimum variance unbiased estimator(MVUE) if $\hat\theta_{\star}\in\theta$ and $Var(\hat\theta_{\star})\leq Var(\hat\theta)\,for\,\hat\theta\in\theta$

**The Cramer-Rao Lower Bound**

Theorem:Let $f_{Y}(y)$ be a continuous pdf with continuous first-order and second-order derivatives.Also,suppose that the set of y values,where $f_{Y}(y)\neq0$,does not depend on $\theta$.$Y^{n}=(Y_{1},Y_{2},...,Y_{n})$ is a random sample with $f_{Y}(y,\theta)$ and let $\hat\theta=h(Y_{1},Y_{2},...,Y_{n})$ be any unbiased estimator of $\theta$.
$$Var(\hat\theta)\geq\frac{1}{nE[(\frac{\partial lnf(y,\theta)}{\partial\theta})^{2}]}=-\frac{1}{nE(\frac{\partial^{2}lnf(y,\theta)}{\partial^{2}\theta})}$$

> 首先要主义这个定理的要求，就是随机变量的取值范围不可以和未知参数有关，这里唯一的例外就是Uniform Distribution。  
> 然后这个定理是用来求一个无偏估计量的最小方差的界限的。  
> 这个定理实际上的逻辑推导过程是这样的：$Var(\hat\theta)\geq\frac{1}{Var(S(\theta,Y^{n}))}=\frac{1}{E(S^{2}(\theta,Y^{n}))}=\frac{1}{nE((\frac{\partial lnf(Y,\theta)}{\partial \theta})^{2})}=-\frac{1}{nE(\frac{\partial^{2}lnf(Y,\theta)}{\partial^{2}\theta})}$

证明的过程就不详细展开了，但是有一些定义以及知识点要说明。

1. $Score\,\,function:S(Y^{n},\theta)=\frac{\partial log\,likelihood funtion}{\partial\theta}=\sum\limits_{i=1}^{n}\frac{\partial lnf(y_{i},\theta)}{\partial\theta}$并且还有一个性质，$E[S(Y^{n},\theta)]=0$。这个score function就是我们在求MLE的时候要使其为0的function
2. Fisher Information实际上就是score function的二阶矩:$I(\theta)=E[S^{2}(Y^{n},\theta)]$。
3. 我们发现：$Var(S(Y^{n},\theta))=E(S^{2}(Y^{n},\theta))-[E(S(Y^{n}),\theta)]^{2}=E(S^{2}(Y^{n},\theta))=I(\theta)$因此我们得到了Fisher information的第一个数学意义：*用来估计MLE方程的方差*。它的直观表示就是，随着收集的数据越来越多，这个方差由于是一个independent sum的形式，也就变得越来越大也就象征着得到的信息越来越多。
4. 当log likelihood function二阶可导的情况下，一般来说(under some specific regularity conditions)很容易证明：$E[S(Y^{n},\theta)^{2}]=-E(\frac{\partial^{2}lnf(y^{n},\theta)}{\partial^{2}\theta})$，于是我们得到了Fisher information的第二个数学意义：*它是log likelihood function在参数真实值处的负二阶导数的期望*
5. Fisher information的第三个数学意义的直观含义是：*它反映了我们对参数估计的准确度，它越大，对参数估计的准确度就越高，即代表了更多的信息*
6. 从这个定理，我们知道Fisher information越大，得到的估计量的最小方差的界限就越小，也就意味着估计越准确。 
7. 一定要注意，在定理中我们使用的并不是整个random sample，而是只用了一个pdf。但是在证明的过程中，我们是从整个random sample开始推导的。

> eg1:$X^{n}=(X_{1},X_{2},X_{3},...,X_{n})\sim Possion(\lambda)$,$f(x)=e^{-\lambda}\frac{\lambda^{x}}{x!},x=0,1,2,...$。求出$\theta$的估计量，并判断是否是MVUE.  
> $L(X,\lambda)=\prod\limits_{i=1}^{n}f(x_{i},\lambda)=\prod\limits_{i=1}^{n}e^{-\lambda}\frac{\lambda^{x_{i}}}{x_{i}!}$  
> $\Rightarrow \rho(x,\lambda)=ln[\prod\limits_{i=1}^{n}e^{-\lambda}\frac{\lambda^{x_{i}}}{x_{i}!}]=\sum\limits_{i=1}^{n}e^{-\lambda}\frac{\lambda^{x_{i}}}{x_{i}!}=-n\lambda+ln\lambda\sum\limits_{i=1}^{n}x_{i}-\sum\limits_{i=1}^{n}lnx_{i}!$  
> $\Rightarrow S(X,\lambda)=-n+\frac{1}{\lambda}\sum\limits_{i=1}^{n}x_{i}=0$  
> $\therefore \hat\lambda=\bar{X_{n}}$ 且显然这是一个无偏估计量  
> 接着我们求一下无偏估计量可以取到的最小方差  
> $Var(\hat\theta)\geq \frac{1}{E[S(Y^{n},\theta)^{2}]}=-\frac{1}{E(\frac{\partial^{2}lnf(y^{n},\theta)}{\partial^{2}\theta})}=-\frac{1}{E(-\frac{1}{\lambda}\sum\limits_{i=1}^{n}X_{i})}=\frac{\lambda}{n}$  
> $\frac{\lambda}{n}=Var(\bar{X_{n}})$,$\therefore \bar{X_{n}}\textrm{is the MVUE for }\lambda$

> eg2:$X^{n}=(X_{1},X_{2},...,X_{n})\sim N(\mu,\sigma^{2})$。给出方差的估计量并判断是否是MVUE。  
> 我们可以使用样本方差，也可以使用MLE的方法来估计方差，得到的是不同的。我们先给出这两个估计量的方差。  
> $Var(S_{n}^{2})=\frac{2\sigma^{4}}{n-1}$,$Var(\hat\theta_{MLE})=Var(\frac{n-1}{n}S_{n}^{2})=\frac{2(n-1)\sigma^{4}}{n^{2}}$  
> 接下来我们来计算一下无偏估计量的最小方差，这里我们使用的方法不同于第一个例子但是是等价的。第一个例子用的是score function，而这里我们只使用一个pdf而不使用random sample。  
> $\frac{\partial^{2}lnf(x,\sigma^{2})}{\partial^{2}(\sigma^{2})}=\frac{1}{2(\sigma^{2})^{2}}-\frac{(x-\mu)^{2}}{(\sigma^{2})^{3}}$  
> $\Rightarrow I(\sigma^{2})=-nE(\frac{\partial^{2}lnf(x,\sigma^{2})}{\partial^{2}(\sigma^{2})})=\frac{n}{2\sigma^{4}}$  
> $Var(\hat\sigma^{2})\geq -\frac{1}{nE(\frac{\partial^{2}lnf(x,\sigma^{2})}{\partial^{2}(\sigma^{2})})}=\frac{2\sigma^{4}}{n}$  
> 显然我们可以看到虽然样本方差是无偏估计量，但是它并不是MVUE。并且我们还发现，MLE虽然有偏但是它的方差比无偏估计量的最小方差还要小。


**Consistency**

1. asymptotically unbiased

之前我们讨论的很多估计量都是对未知参数的有偏估计，但是其中大多数估计量的期望在n趋向于无穷的时候是无偏的，这就叫做*渐进无偏性*

2. consistency

Definition:An estimator $\hat\theta_{n}=h(W_{1},W_{2},...,W_{n})$ is said to be consistent for $\theta$ if it converges in probability to $\theta$---that is,if for all $\epsilon>0$
$$lim_{n\rightarrow\infty}P(|\hat\theta_{n}-\theta|<\epsilon)=1$$

> eg:$Y^{n}=(Y_{1},Y_{2},...,Y_{n})\sim Uniform distribution$,$f_{Y}(y,\theta)=\frac{1}{\theta},0\geq y\geq\theta$.Find the MLE;is it unbiased;is it asymptotically unbiased;is it consistent?  
> 首先MLE我们需要使用到次序统计量，这里就不详细说了。$\hat\theta_{MLE}=Y_{Max}=Y_{(n)}$  
> $E(\hat\theta_{MLE})=\frac{n}{n+1}\theta$  
> $lim_{n\rightarrow\infty}E(\hat\theta_{MLE})=\theta$，显然是渐进无偏的  
> $P(|\hat\theta_{MLE}-\theta|<\epsilon)=P(\theta-\epsilon<y_{(n)}<\theta+\epsilon,0\geq y_{(n)}\geq\theta)=P(\theta-\epsilon<y_{(n)}<\theta)=\int_{\theta-\epsilon}^{\theta}\frac{n\cdot y^{n-1}}{\theta^{n}}dy=1-(\frac{\theta-\epsilon}{\theta})^{n}$  
> $\therefore lim_{n\rightarrow\infty}P(|\hat\theta_{MLE}-\theta|<\epsilon)=1$  
> 或者我们可以使用马尔科夫不等式来得到这个结果，因为这个概率式子是可以联系到马尔科夫不等式的，这里就不展开了。

**Sufficient Estimators**

Definition[sufficient statistic]:Let $X^{n}$ be a random sample from sufficient statistic for $\theta$ if the conditional distribution of the sample $X^{n}=x^{n}$ given that the value of the statistic T(X^{n})=T(x^{n}) does not depend on $\theta$.That is 
$$f_{X^{n}|T(X^{n})}[x^{n}|T(x^{n}),\theta]=h(x^{n})\textrm{ for all possible }\theta$$



#Chapter 6 Hypothesis Testing

##Null hypothesis and alternative hypothesis

首先要弄明白“假设”是什么，在这里假设指的其实就是*两个相互冲突的针对于某个分布、针对某个参数的描述*。因此“假设检验”要做的就是我们要从两个描述中选择一个我们认为正确的。

现实中其实我们都在进行假设检验的过程。比如，我们想要知道某个汽车品牌的添加剂是否对于某型号汽车节油有功效，那么这个节省油vs不节省油就是一对相互冲突的描述。并且如果我们抽象一下，其实这个节油不节油就是想看看耗油的均值是不是比这个车型给出的初始数据要低：
$$H_{0}:\mu=\mu_{0}\quad\textrm{原假设(null hypothesis)}$$
$$v.s.\quad H_{1}:\mu<\mu_{0}\quad\textrm{备择假设(alternative hypothesis)}$$

> 一般来说，原假设是一个比较精确的等式，而备择假设则是一个不等式，比较宽泛。  
> 单边备择假设和双边备择假设：单边备择假设就是备择假设中是用小于或者大于的，而双边备择假设就是用不等于符号的。它们在检验中会稍微有一点区别。

那么下一步我们应该怎么做呢？很自然地，我们肯定想先估计一下这个均值是多少，然后再做决定。这个时候就会用到我们之前学的参数估计的知识了！可是估计完之后呢？还是很自然地我们就想，如果这个估计值比$\mu_{0}$小很多，我们就会觉得“嗯，看来是省油的”；如果这个估计值离$\mu_{0}$很近，那我们就会觉得“看来是没什么省油的效果嘛”。

那么问题就来了：这个估计值小到多少我们可以觉得它是省油的（认为备择假设正确），这个估计值在哪个范围我们可以觉得它是没有省油效果的（认为原假设正确）呢？

##Two kinds of error

现在我们先穷举一下如果我们进行了选择，将有多少种可能：

1. 在原假设正确的情况下接受原假设
2. 在原假设错误的情况下拒绝原假设
3. 在备择假设正确的情况下接受原假设
4. 在备择假设正确的情况下拒绝原假设

这四种情况中，有两种错误，即我们所要定义的*[第一类错误：拒真]*和*[第二类错误：受假]*

$$\textrm{Type I error:reject }H_{0}\textrm{ when }H_{0}\textrm{ is true}$$
$$\textrm{Type II error:fail to reject }H_{0}\textrm{ when }H_{1}\textrm{ is true}$$

既然有可能出现这样的错误，我们当然会想要避免它们。如何能够做到避免呢？这时候你可以观察这四种情况，其实它们都是*事件*。之所以说它们是事件，是因为我们在最开始先估计了均值，然后我们使用样本均值在某次取值能否小于某个值来完成*拒绝*或者*不拒绝*的选择。而样本均值是一个估计量，也就是一个随机变量，那么就带有了随机性，因此这四种情况就是*事件*了，这时候避免的方法就很显然了，通过控制犯错误的**概率**来避免错误发生。

如果扩展到任意的一次假设检验过程中，我们永远要先进行估计，所以永远存在着这样四种情况，估计量总是带有随机性的，所以这种控制犯错概率的方法就是一种一般的方法了。

我们现在知道要控制发生错误的概率，但问题是这里有两种类型的错误，我们应该怎么控制呢？是单独控制一类错误还是单独控制二类错误，还是有一起控制的方法呢？

1. 一类错误和二类错误的发生概率是相互矛盾的，如果降低一类错误的发生概率则必然会提高二类错误的发生概率。
2. 一类错误是绝对可控的，而二类错误则无法控制。这里的原因是由于原假设是一个精准的等式，而备择假设是一个宽泛的不等式，这就导致当我们求条件概率的时候，二类错误的发生概率没办法求出。因此我们会首先控制一类错误。
3. 因为我们首先控制一类错误，所以这就凸显除了原假设的重要性，所以我们在设立假设的时候应该把更重要的放在原假设。

**Power function**

$$P(fail\,to\,reject\,H_{0}|H_{1}\,is\,ture)=\beta$$

> 我们知道了检验是通过控制一类错误的发生概率来进行的，但是二类错误我们也不能忽略。因此我们也要来谈一谈二类错误。一个重要的点是，我们控制一类错误来找到critical value，二类错误是基于这个critical value来计算的。

$$power\,function=1-\beta$$
如果我们拿均值检定作为例子的话，容易发现：
$$power function=f(\mu_{1}),\alpha为外生变量$$

> power function有两个作用，首先它能够展示在不同的$H_{1}$的情况下的二类错误发生的概率，其次它还有一个很重要的作用就是对不同的检定统计量(估计量)进行比较。假设我们有两个检定统计量它们都可以做检定，那么我们通过控制一类错误的发生概率，可以得到critical value，但是这两个检定统计量在相同的$\alpha$下，二类错误发生的概率是不同的。我们当然希望一类、二类错误的发生概率都较低的，因此我们会选择这两个检定统计量中power function更小的。


##几种检验的方法

**Critical value**

In practice,in order to find an appropriate cutoff value so that we can make a choice,we control the probability of making Type I error under some *prespecified* level $\alpha$:
$$P(reject\,\,H_{0}|H_{0}\,is\,true)=\alpha$$
$\alpha$ is called the level of significance of the test.

> 这里的$\alpha$就是我们在上一节说到的要控制的犯错误的概率，如果我们设置这个$\alpha$越小说明我们越不能容忍一类错误的发生，那么相应的二类错误的发生概率就会增加。  
> 不同的$\alpha$将会反解得到不同的critical value

导致发生一类错误的方向的一系列值就是critical region，而那个交界点就是critical value。当我们的估计量取值落入critical region的时候我们就要拒绝原假设。

> 逻辑：我们控制一类错误在一个很小的概率下，也就是说估计量取这一部分的值的概率是很低的。但是当实际情况中确实发生了，它就相当于是小概率事件，或者说“事出反常必有妖”。这种时候我们认为实际上这个估计量不服从这个分布才出现了这样的情况，也就是说原假设是错误的。

**P-value**

$$P-value=\alpha_{0}=P(Z\,is\,as\,extrem\,as\,or\,more\,extrem\, than\,z_{obs}|H_{0}\,is\,true)$$

这种方法的思路和上一个其实是一样的，只不过它更加直接。这种方法直接去计算在原假设成立的情况下估计量的观测值发生的极端性有多高，然后拿它和$\alpha$进行比较，如果比$\alpha$还要小，那就等同于发生了小概率事件，那么就认为原假设是错误的。


##Generalized likelihood Ratio Test(GLRT)

我们在讲这个test之前先给出假设检验的一个步骤总结：

1. parameter of interest and the associated hpyothesis testing.
2. Test statistic and its distribution under $H_{0}$ is true
3. 
4. 
5. 

> 我之所以只写前两个是因为后三个只涉及到计算，并不是困难的地方。假设检验中最困难的是前两个步骤，但是我们使用的例子一直是均值，所以感觉不出难度。实际上，如果给出一个实际问题，那么我们首先就要找到我们所关心的参数、并做出适当的假设，然后我们必须得到在原假设正确的情况下检定统计量的分布！这十分重要！

所以我们现在讨论一个更一般的情况，即$\theta=\theta_{0}$，它既不是均值也不是什么p，而只是一个一般化的参数。















