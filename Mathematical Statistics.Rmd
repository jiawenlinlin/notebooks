---
title: "Mathematical Statistics"
author: "林嘉文"
date: "2017年8月26日"
output: html_document
---
首先我们明确我们所学的是参数统计，与之相对应的是非参数统计。它们都会涉及到*参数估计*和*假定检验*，这也是数理统计要做的两件最主要的事情。参数统计与非参数统计的区别就在于，参数统计对于随机变量的分布是有假设的，而非参数统计则相对来说缺少对于分布的假设,相对更robust。

但是我们肯定想问，到底我们是在干什么呢？统计所在做的分为描述性统计和推断性统计(describetive statistics and inference statistics),我们现在说的是推断性统计到底在做什么。推断性统计其实都是为了研究“某个事情的规律”，这里的“某个事情”泛指某个随机变量，“规律”指的就是随机变量的分布。这世间很多东西可以简化为随机变量的各种取值，因此我们最想知道的就是这个随机变量的分布，而推断性统计就是为了将这个随机变量的分布找出来。对于随机变量而言，得到分布就得到了一切。

但是我们永远无法确切知道分布到底是什么样子的，因此我们只能*估计*，估计完了之后还要*检定*这个估计是否正确。



#Chapter 5 Parameter Estimation

* 样本必须iid，并具有代表性。
* 从大量数据中得出分布，有两种方法，一种是参数估计方法，一种是非参数估计方法，分别对应于参数统计和非参数统计。

##参数估计基本介绍

参数估计方法就是我们假设随机变量服从某个分布$f_{X}(x)=f(x,\theta)$,其中$f_{X}()$是已知函数而参数$\theta$是未知的，从而我们的任务从估计其分布变成估计参数，这里的$\theta$是一个概括，它可以是一个或者多个未知参数。

> 如果$f_{X}(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}$,则$\theta=(\mu,\sigma)$  
> 从这里我们就要记住我们现在的任务是估计一个*固定的*、*未知的*值。

##Statistics

定义：$X^{n}=(X_{1},X_{2},X_{3},...,X_{n})$是从总体中取出的n个iid随机变量。$T(X^{n})=T(X_{1},X_{2},X_{3},...,X_{n})$则称为一个*统计量(statistic)*

> 统计量也是一个随机变量，因为它实际上是对$X^{n}$加了一个法则。因此统计量也具有概率分布，也有期望、方差这些性质。  
> 统计量中不能出现未知参数，不然不叫统计量。统计量的分布有可能已知有可能未知。与之相对应的一个东西叫做*枢轴量*，枢轴量是含有未知参数的随机变量，但是它的分布是已知的。  
> 为什么要弄这么一个统计量呢？在我看来，其实统计量就是用来估计参数的。它也符合我们的一个逻辑：我们只拥有许多数据，这些数据是iid样本$X^{n}$的一次（或多次）取值，那么我们构造的统计量也能得到相应的取值，如果这些统计量被证明是一些参数的好的估计，那么我们就可以用它们来估计参数了。  
> eg:$\bar{X_{n}}=\frac{\sum_{i=1}^{n}X_{i}}{n}$,$S_{n}^{2}=\frac{\sum_{i=1}^{n}(X_{i}-\bar{X_{n}})^{2}}{n-1}$,它们分别是样本均值和样本方差，但是实际上它们就是统计量。它们是由iii样本$X^{n}$构成的函数，它们是随机变量。


**样本均值$\bar{X_{n}}$**

样本均值，就是对样本取平均。
$$\bar{X_{n}}=\frac{1}{n}\sum\limits_{i=1}^{n}X_{i}$$
那么我们就会自然想知道它的期望、方差以及分布是什么，
$$E(\bar{X_{n}})=E(\frac{1}{n}\sum\limits_{i=1}^{n}X_{i})=\frac{1}{n}\sum\limits_{i=1}^{n}E(X_{i})=\frac{1}{n}\sum\limits_{i=1}^{n}\mu=\mu$$

> 因为$X_{i}$是iid的，所以得到这个结果。可以看到样本均值的期望就是$X_{i}$的期望$\mu$。因此我们把样本均值称为是总体均值$\mu$的无偏估计。

$$Var(\bar{X_{n}})=Var(\frac{1}{n}\sum\limits_{i=1}^{n}X_{i})=\frac{1}{n^{2}}Var(\sum\limits_{i=1}^{n}X_{i})=\frac{1}{n^{2}}\sum\limits_{i=1}^{n}Var(X_{i})=\frac{\sigma^{2}}{n}$$

> 求解过程中，因为$X_{i}$是独立同分布的，因此所有的协方差均为0。可以看到最后样本均值的方差和$X_{i}$的方差不同，它衡量的是$\bar{X_{n}}$这一随机变量的波动程度。  
> 当n越大，$Var(\bar{X_{n}})$越小。当$n\rightarrow\infty$，$Var(\bar{X_{n}})\rightarrow 0$,换句话说就是当n趋向无穷时，样本均值就是总体均值。


Theorem:suppose $X^{n}=(X_{1},X_{2},...X_{n})$是iid正态分布的随机样本，均值为$\mu$，方差为$\sigma^{2}$，那么就有
$$\bar{X_{n}}\sim N(\mu,\frac{\sigma^{2}}{n})$$

> 这个其实都不能算是一个theorem，因为这个实际上就是我们在概率论中说的sum of independent R.V.的结论的使用。

Central Limit Theorem:$X^{n}=(X_{1},X_{x},...,X_{n})$是iid的随机样本，均值为$\mu$，方差为$\sigma^{2}$，$\bar{X_{n}}=\frac{1}{b}\sum\limits_{i=1}^{n}X_{i}$,则
$$Z_{n}=\frac{\bar{X_{n}}-\mu}{\frac{\sigma}{\sqrt{n}}}\xrightarrow{d}N(0,1)$$

> 中心极限定理并不要求$X_{i}$的任何分布信息，只需要n足够大。

**样本方差$S_{n}^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}(X_{i}-\bar{X_{n}})^{2}$**

我们的第一反应其实是仿照样本均值，分母似乎是n而不是(n-1)，但是我们可以证明分母是(n-1)才能使其是总体方差的无偏估计。

$$S_{n}^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}(X_{i}-\bar{X_{n}})^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}[(X_{i}-\mu)-(\bar{X_{n}}-\mu)]^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}[(X_{i}-\mu)^{2}-2(X_{i}-\mu)(\bar{X_{n}}-\mu)+(\bar{X_{n}}-\mu)^{2}]$$
$$\Rightarrow S_{n}^{2}=\frac{1}{n-1}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-2\sum\limits_{i=1}^{n}(X_{i}-\mu)(\bar{X_{n}}-\mu)+\sum\limits_{i=1}^{n}(\bar{X_{n}}-\mu)^{2}]=\frac{1}{n-1}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-2(\bar{X_{n}}-\mu)\sum\limits_{i=1}^{n}(X_{i}-\mu)+n\cdot(\bar{X_{n}}-\mu)^{2}]$$
$$\Rightarrow S_{n}^{2}=\frac{1}{n-1}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-2(\bar{X_{n}}-\mu)(\sum\limits_{i=1}^{n}X_{i}-n\cdot\mu)+n\cdot(\bar{X_{n}}-\mu)^{2}]=\frac{1}{n-1}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-2(\bar{X_{n}}-\mu)\cdot n\cdot(\bar{X_{n}}-\mu)+n\cdot(\bar{X_{n}}-\mu)^{2}]$$
$$\Rightarrow S_{n}^{2}=\frac{1}{n-1}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-n\cdot(\bar{X_{n}}-\mu)^{2}]$$
$$\therefore E(S_{n}^{2})=\frac{1}{n-1}E[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-n\cdot(\bar{X_{n}}-\mu)^{2}]=\frac{1}{n-1}(n\cdot\sigma^{2}-n\cdot\frac{\sigma^{2}}{n})=\sigma^{2}$$

> 显然我们可以看到，如果分母不是(n-1)，那么样本方差的期望就不是$\sigma^{2}$啦！

为了推出样本方差的方差和分布，我们需要证明：
$$\textrm{Suppose }X^{n}\textrm{ is a iid }N(\mu,\sigma^{2})\textrm{ random sample.Then for any n>1},S_{n}^{2}\,\,and\,\,\bar{X_{n}}\textrm{ are mutually independent.That is }S_{n}^{2}\bot\bar{X_{n}}$$

> 这个我们就不详细证了，我们说一下大致的思路。等价于要证明$(X_{1}-\bar{X_{n}},X_{2}-\bar{X_{n}},...,X_{n}-\bar{X_{n}})\bot X_{n}$,则我们进行一次换元，以简化字符，然后通过$f_{X,Y}(x,y)=h(x)\cdot g(y)$这个推论来证明独立。  
> 我们会用到雅可比矩阵的知识，因为我们需要在换元之后得到新的联合分布。  
> 这个理论要求X必须来自正态分布，在证明中要用到。所以一定要注意这个前提。

Theorem:$\frac{(n-1)S_{n}^{2}}{\sigma^{2}}\sim \chi_{n-1}^{2}$

需要说明的是，首先要求X来自一个正态分布，那么这个随机样本的样本方差有这样一个结论，其中$X_{n-1}^{2}$是自由度为(n-1)的卡方分布。

$$\frac{(n-1)S_{n}^{2}}{\sigma^{2}}=\sum\limits_{i=1}^{n}\frac{(X_{i}-\bar{X_{n}})^{2}}{\sigma^{2}}=\sum\limits_{i=1}^{n}\frac{[(X_{i}-\mu)-(\bar{X_{n}}-\mu)]^{2}}{\sigma^{2}}=\frac{1}{\sigma^{2}}[\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}-n\cdot(\bar{X_{n}}-\mu)^{2}]$$
$$\Rightarrow \frac{(n-1)S_{n}^{2}}{\sigma^{2}}=\sum\limits_{i=1}^{n}(\frac{X_{i}-\mu}{\sigma})^{2}-n\cdot (\frac{\bar{X_{n}}-\mu}{\sigma})^{2}=\sum\limits_{i=1}^{n}(\frac{X_{i}-\mu}{\sigma})^{2}-(\frac{\bar{X_{n}}-\mu}{\frac{\sigma}{\sqrt{n}}})^{2}$$
$$\Rightarrow \textrm{令 }U=\sum\limits_{i=1}^{n}(\frac{X_{i}-\mu}{\sigma})^{2},Z=(\frac{\bar{X_{n}}-\mu}{\frac{\sigma}{\sqrt{n}}})^{2},W=\frac{(n-1)S_{n}^{2}}{\sigma^{2}}$$
$$\therefore U=Z+W$$
$$M_{U}(t)=M_{Z+W}(t)=E[e^{(z+w)t}]=E(e^{zt+wt})=\int\int e^{zt+wt}f_{Z,W}(z,w)dzdw=\int e^{zt}f(z)dz\int e^{wt}f(w)dw=(1-2t)^{-\frac{1}{2}}M_{W}(t)$$
$$\because M_{U}(t)=(1-2t)^{-\frac{n}{2}}\quad\therefore M_{W}(t)=(1-2t)^{-\frac{n-1}{2}}$$
$$\therefore \frac{(n-1)S_{n}^{2}}{\sigma^{2}}\sim \chi_{n-1}^{2}$$

> 在我们使用矩母函数的时候，我们把联合分布拆开就用到了样本均值和样本方差独立的条件。  
> $If\,\,X\sim N(0,1),then\,\,X^{2}\sim \chi_{1}^{2}$  
> $If\,\,X_{i}\sim N(0,1),iid,then\,\,\sum_{i=1}^{n}X_{i}^{2}\sim \chi_{n}^{2}$  
> 为什么这里自由度是(n-1)呢，其实也是有讲究的。假设有$W_{n}^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}(X_{i}-\mu)^{2}$,则有$\frac{(n-1)W_{n}^{2}}{\sigma^{2}}=\sum\limits_{i=1}^{n}(\frac{X_{i}-\mu}{\sigma})^{2}\sim \chi_{n}^{2}$。但是因为我们在$S_{n}^{2}$里面把均值换成了样本均值，就会丢失了一个信息，所以自由度减少1.

有了分布之后，方差就很好计算了。因为

$$E(\chi_{n-1}^{2})=n-1,Var(\chi_{n-1}^{2})=2(n-1)$$
$$\Rightarrow Var(\frac{(n-1)S_{n}^{2}}{\sigma^{2}})=2(n-1)$$
$$\Rightarrow \frac{(n-1)^{2}}{\sigma^{4}}Var(S_{n}^{2})=2(n-1)$$
$$\therefore Var(S_{n}^{2})=\frac{2\sigma^{4}}{n-1}$$


##Two classical estimation methods

前面我们讲的样本均值和样本方差实际上也可以作为均值和方差的估计量，但是它们是我们从直觉中找到的统计量，而不是通过某种方法找到的。现在我们要介绍两种最主要的参数估计方法。

**Maximum likelihood estimation**

*本质：观察到已经发生的事件，求得使这件事发生概率最大的参数的值。*

> 这种方法有一个很本质的想法，比如说一个池塘有A,B两种鱼，你随便捞10条鱼，其中8条是A，2条是B，从而你估计池塘中80%是A鱼;又比如说拿一枚硬币投掷30次，结果是20次为字朝上，10次花朝上，从而你估计字朝上的概率是$\frac{2}{3}$。  
> 概率论是已知参数求概率，而数理统计是由观察到的数据估计参数。

The procedure to find a maximum likelihood estimator for $\theta$

1. 得到$L(\theta)$,$L(\theta)=\prod\limits_{i=1}^{n}f_{Y}(yi,\theta)$.
2. 对$L(\theta)$取对数,$\rho(\theta)=ln(L(\theta))$（方便运算，尤其对于指数类的概率分布函数。并且ln是单调递增的，不会影响到$L(\theta)$的极值点）
3. 解等式$\frac{d\rho(\theta)}{d\theta}=0$，求得极值点
4. 验证二阶导是否小于0，保证极值点为极大值点。（这一步一般来说不需要）

> $L(\theta)被称为似然函数(likelihood function),要得到这个东西，前提就是我们已知Y的分布，所以最大似然估计很显然就是参数估计的方法。$  
> 实际上我们在求的东西是，$\hat{\theta}=arg\,max_{\theta}L(\theta|Y_{1},Y_{2},...Y_{n})$。在随机样本没有取值之前，这个表达式是一个随机变量，也就是一个estimator，但是当随机样本取值之后，这个estimator也会取一个值，也就是estimate。

> eg1:我们以掷硬币为例子，我们想要估计的很显然就是伯努利分布中的那个p。  
> 对于伯努利分布，$f_{X}(x)=p^{x}(1-p)^{1-x},x\in\{0,1\}$  
> $\Rightarrow L(p)=f_{X}(x_{1})f_{X}(x_{1})\cdots f_{X}(x_{n})=p^{\sum\limits_{i=1}^{n}x_{i}}(1-p)^{n-\sum\limits_{i=1}^{n}x_{i}}$  
> $\Rightarrow\rho(p)=ln(L(p))=\sum\limits_{i=1}^{n}x_{i}ln(p)+(n-\sum\limits_{i=1}^{n}x_{i})ln(1-p)$  
> $\Rightarrow\frac{d\rho(p)}{dp}=\sum\limits_{i=1}^{n}x_{i}\frac{1}{p}-(n-\sum\limits_{i=1}^{n}x_{i})\frac{1}{1-p}=\frac{(1-p)\sum\limits_{i=1}^{n}x_{i}-p(n-\sum\limits_{i=1}^{n}x_{i})}{p(1-p)}=0$  
> $\therefore\quad \hat{p}=\frac{1}{n}\sum\limits_{i=1}^{n}x_{i}$  
> 这个就是p的估计量，它首先是一个随机变量，其实就是样本均值。当我们进行实验得到数据之后，就可以得到一个具体的估计值。

> eg2:当未知参数不止一个的时候，例如有两个参数则要对两个参数求偏导并联立求解。$X_{i}\sim N(\mu,\sigma),X^{n}=(X_{1},X_{2},...,X_{n})$。求均值和方差的最大似然估计量。  
> $f_{X}(X)=\frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-frac{(x-\mu)^{2}}{2\sigma^{2}}}$  
> $\Rightarrow L(\mu,\sigma^{2})=\prod\limits_{i=1}^{n}f_{X}(x_{i},\mu,\sigma^{2})=\frac{1}{(2\pi\sigma^{2})^{\frac{n}{2}}}e^{-\frac{\sum\limits_{i=1}^{n}(x_{i}-\mu)^{2}}{2\sigma^{2}}}$  
> $\Rightarrow \rho(\mu,\sigma^{2})=ln(L(\mu,\sigma^{2}))=-\frac{n}{2}ln(2\pi\sigma^{2})-\frac{\sum\limits_{i=1}^{n}(x_{i}-\mu)^{2}}{2\sigma^{2}}$  

$$\left\{
\begin{array}{1}
\frac{d\rho(\mu,\sigma^{2})}{d\mu}=\frac{\sum\limits_{i=1}^{n}(x_{i}-\mu)}{\sigma^{2}}=0\\ \frac{d\rho(\mu,\sigma^{2})}{d\sigma^{2}}=-\frac{n}{2}\cdot\frac{1}{\sigma^{2}}+\frac{\sum\limits_{i=1}^{n}(x_{i}-\mu)^{2}}{2}\cdot\frac{1}{\sigma^{4}}=0\\
\end{array}
\right.$$

$$
\left\{
\begin{array}{1}
\hat{\mu}=\bar{X_{n}}\\
\hat{\sigma^{2}}=\frac{1}{n}\sum\limits_{i=1}^{n}(X_{i}-\bar{X_{n}})^{2}\\
\end{array}
\right.$$  

> P.S.一定要注意，如果是对$\sigma^{2}$进行估计，那么求偏导的时候就要把整个当做一个整体。  
> 可以看到，用MLE来估计的方差的分母是n而不是样本方差中的(n-1)。所以显然它是一个有偏的估计量。

当无法使用求导来求极大值时，就应该使用其他方法来求。

> eg3:$f_{Y}(y)=e^{-(y-\theta)},y\geq\theta,\theta>0,Y^{n}=(Y_{1},Y_{2},...,Y_{n}).$  
> $L(\theta)=\prod\limits_{i=1}^{n}e^{-(y_{i}-\theta)}$  
> $\Rightarrow \rho(\theta)=ln(L(\theta))=\sum\limits_{i=1}^{n}\theta-y_{i}$  
> $\frac{d\rho(\theta)}{d\theta}=n>0$  
> 显然这里就没法说令其等于0，因为这个是一个递增函数没有极值点。但是因为它是递增的，如果我们在其定义域中取最大值就可以使函数最大化了。    
> $\because \theta\leq y,\quad \therefore \theta\leq min(y_{i})=y_{(1)}$  
> $\therefore \hat{\theta}=y_{(1)}$


**Moments Estimation**

首先我们要回忆一下关于矩的一些知识：

$$E(X^{k})=
\left\{
\begin{array}{11}
\sum_{x}x^{k}f(x) & discrete R.V.\\
\int x^{k}f(x)dx & continuous R.V.\\
\end{array}
\right.$$

矩估计的使用方法：

1. 首先，你先要判断一共要估计多少个未知参数。如果呀估计s个未知参数，就要用到s阶矩。分别计算s阶矩的表达式，它们由着s个未知参数的代数式表示。
2. 我们所要做的仅仅是用样本矩去替代总体矩,作为总体矩的估计，然后反解出各个参数的估计表达式即可（解方程组）

*j阶样本矩*：
$$\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i}^{j}$$

> eg1:Suppose that $Y^{n}=(Y_{1},Y_{2},...,Y_{n})$ is a random sample of size n from a normal distribution with mean $\mu$ and variance $\sigma^{2}$.Estimate these two parameters.  
> $\mu=E(Y),\sigma^{2}=E(Y^{2})-(E(Y))^{2}$  
> $\Rightarrow \hat{\mu}=\hat{E(Y)}=\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i},\hat{\sigma^{2}}=\hat{E(Y^{2})}-(\hat{E(Y)})^{2}=\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i}^{2}-(\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i})^{2}$  
> 这就是矩估计量

> eg2:Suppose that $Y^{n}=(Y_{1},Y_{2},...,Y_{n})$ is a random sample of size n from a general gamma distribution with the pdf $f_{Y}(y,\alpha,\beta)=\frac{1}{\tau(\alpha)\beta^{\alpha}}y^{\alpha-1}e^{-\frac{y}{\beta}},for\,\,y>0$,where $\alpha,\beta>0$ and $\tau(\alpha)=\int_{0}^{\infty}t^{\alpha-1}e^{-t}dt$.Estimate $\alpha,\beta$  
> $E(Y)=\alpha\beta,Var(Y)=\alpha\beta^{2}$  
> $\Rightarrow \beta=\frac{E(Y^{2})-(E(Y))^{2}}{E(Y)},\alpha=\frac{(E(Y))^{2}}{E(Y^{2})-(E(Y))^{2}}$  
> $\therefore \hat{\beta}=\frac{\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i}^{2}-(\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i})^{2}}{\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i}},\hat{\alpha}=\frac{(\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i})^{2}}{\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i}^{2}-(\frac{1}{n}\sum\limits_{i=1}^{n}Y_{i})^{2}}$

*所以你会发现MME非常方便，因为它的过程非常简单不想MLE那样需要求极值之类的，同时MME没有直接用到分布的信息。但是我们可以看到，因为它的简便性，它的精确度就没有MLE那么高，毕竟它只使用了矩的信息，而没有使用整个分布的信息。*



##Interval Estimation

之前我们所做的都是point estimation(点估计),也就是说我们每次我们进行一次估计，因为估计量是一个随机变量，它就会得到一次取值，是一个点。但是这样就存在一个问题：好比说有一个无偏的估计量，它的期望就是这个未知的参数值，这时候如果只进行一次观察得到估计量的一个实现值，我们就无法知道这个实现值到底离它的均值是近还是远，尽管按理来说大部分的实现值会在期望附近出现。那我们可能又会问了，那就多观察几次呗？但是一般来说我们只会对随机样本进行一次取值。

To this end,we usually construct a confidence interval to quantify the amount of uncertainty in an estimator.By looking at the width of a confidence interval,we can get a good sense of the estimators precision.

> 说白了，区间估计从估计的角度来说是对点估计的改进。它的改进在于减少了点估计的不确定性，这个不确定性就体现在我刚刚说的在一次取值中无法知道它离期望是远是近。但是用区间估计的话，就会控制住这个不确定性。

Given a confidence level $1-\alpha\in[0,1]$,we have two statistics
$$\textrm{lower bound: }L(X_{1},X_{2},...,X_{n})\textrm{ and upper bound: }U(X_{1},X_{2},...,X_{n})$$
such that
$$P_{\theta_{0}}\{L(X_{1},X_{2},...,X_{n})\leq\theta_{0}\leq U(X_{1},X_{2},...,X_{n})\}=1-\alpha$$
We say that $[L(X_{1},X_{2},...,X_{n}),U(X_{1},X_{2},...,X_{n})]$ is the confidence interval of the unknown parameter $\theta_{0}$ with confidence level $1-\alpha$

> 注意了，L和U其实都是随机变量，都是统计量。相较于点估计只用了一个随机变量，现在我们用两个随机变量去框住一个范围。

问题在于我们如何能够构造出confidence interval呢？我们必须回到自信区间的定义去寻找方法。可以看到我们只要能够实现这样的一个概率等式，那么我们就算找到了L和U。关键点有两个：

1. 区间估计是点估计的升级改进，所以会和点估计有一定的联系
2. 枢轴量

> eg1:$X_{i}\sim N(\mu,\sigma^{2})$,其中方差已知，我们想要求得均值的区间估计。那么我们首先想到的当然是  
> $$\frac{\bar{X_{n]}}-\mu}{\frac{\sigma}{\sqrt{n}}}\sim N(0,1)$$  
> $$\Rightarrow P(-Z_{\frac{\alpha}{2}}\leq\frac{\bar{X_{n}}-\mu}{\frac{\sigma}{\sqrt{n}}}\leq Z_{\frac{\alpha}{2}})=1-\alpha$$  
> $$\Rightarrow P(\bar{X_{n}}-Z_{\frac{\alpha}{2}}\cdot\frac{\sigma}{\sqrt{n}}\leq\mu\leq\bar{X_{n}}+Z_{\frac{\alpha}{2}}\cdot\frac{\sigma}{\sqrt{n}})=1-\alpha$$  
> $$\therefore [\bar{X_{n}}-Z_{\frac{\alpha}{2}}\cdot\frac{\sigma}{\sqrt{n}},\bar{X_{n}}+Z_{\frac{\alpha}{2}}\cdot\frac{\sigma}{\sqrt{n}}]\textrm{就是我们要找的自信度为}(1-\alpha)\textrm{的自信区间}$$  
> 可以看到，首先我们会先找均值的点估计量，但是最关键的是概率等式中的那个枢轴量，它含有未知参数$\mu$，但是我们知道它的分布，知道它的分布就可以求概率了！！！然后再把未知参数放在中间就好了。

> eg2:如果X不服从正态分布且方差已知，我们仍然想估计它的均值。那么由中心极限定理我们还是有  
> $$\frac{\bar{X_{n}}-\mu}{\frac{\sigma}{\sqrt{n}}}\xrightarrow{d}N(0,1)$$  
> 后面的过程和第一个例子是相同的，关键点还是我们用CLT得到了一个类似于枢轴量的东西。也就是我们必须得到一个已知的分布。

> eg3:在前两个例子中，方差总是已知的。如果方差未知我们可以用样本方差替代总体方差。当X是正态分布时，那个枢轴量将服从T分布；当X是未知分布时，通过中心极限定理以及Slutsky's Theorem可以得到那个枢轴量仍然依概率收敛于标准正态分布。

> eg4:Let $X\sim Bin(n,p)$.We are interested in the confidence interval of p.Note that $X=\sum\limits_{i=1}^{n}Y_{i}$ with $Y_{i}$ iid from Bernoulli(p).  
> $$\textrm{由CLT }，\frac{\frac{X}{n}-p}{\sqrt{\frac{p(1-p)}{n}}}\xrightarrow{d}N(0,1)$$  
> $$\Rightarrow P(-Z_{\frac{\alpha}{2}}\leq\frac{\frac{X}{N}-p}{\sqrt{\frac{p(1-p)}{n}}}\leq Z_{\frac{\alpha}{2}})=1-\alpha$$  
> 这时候你发现没有办法把p单独分离出来，无法得到自信区间的定义式。但是我们可以通过Slutsky's Theorem再构造一个依概率收敛于标准正态分布的枢轴量。具体就不展开了。


最后，我们还要说一下对于区间估计的理解。所有的理解都是基于自信区间的定义式展开的，因为它是一个概率等式，那么这个自信度$(1-\alpha)$的意思就是概率的意思。比如说自信度为95%，那意思就是如果我*能够*重复观察10000次，那么其中9500次均值会落在这个区间内，如果我*能够*重复观察100000次，那么其中95000次均值会落在这个区间内。但是，还是之前的那句话，*一般来说我们只进行一次观察*，对于这一次观察这个均值到底落不落进这一次的实现范围，只有两种情况：要么落进去，要么不落进去。而这个自信度越高，说明落进去的概率越大，那么对应于某一次来说我们*更加相信*它是落进去的。至于到底落进去没有，只有上帝知道了。


##Properties of Estimators

之所以我们想要了解估计量的性质，是因为我们想知道：哪一个估计量更好？因为估计量实际上就是统计量，因此它是一个随机变量，也就会有期望、方差、分布这些性质，这也是我们用来判断的标准。

**Unbiasedness**

Definition:Suppose $Y^{n}=(Y_{1},Y_{2},...,Y_{n})$ is a random sample with pdf $f_{Y}(y,\theta)$,$\theta$ is an unknown parameter.Then $\hat{\theta}=h(Y_{1},Y_{2},...,Y_{n})$ is called unbiased estimator if
$$E(\hat{\theta})=\theta$$
and the bias of $\hat{\theta}$ is defined by
$$Bias(\hat{\theta})=E(\hat{\theta})-\theta$$

> eg:$Y_{1},Y_{2},...,Y_{n}\sim f_{Y}(y,\theta)=\frac{2y}{\theta^{2}},0\leq y\leq\theta$.Give the MLE and MME of $\theta$ and distinguish their unbiasedness.  
> 我们直接给出两种估计量，  
> $$\hat{\theta_{MLE}}=Y_{Max}=Y_{(n)},\hat{\theta_{MME}}=\frac{3}{2}\cdot\bar{Y_{n}}$$  
> $$E(\hat{\theta_{MME}})=\frac{3}{2n}E(\sum\limits_{i=1}^{n}Y_{i})=\frac{3}{2}E(Y_{i}),E(Y_{i})=\int_{0}^{\theta}Y\cdot f_{Y}(y,\theta)dy=\frac{2}{3}\theta$$  
> $$\therefore E(\hat{\theta_{MME}})=\theta\quad \textrm{MME为无偏估计量}$$
> $$E(\hat{\theta_{MLE}})=E(Y_{(n)})=\frac{2n}{2n+1}\theta$$  
> $$\therefore \textrm{MLE是有偏估计量且 } Bias(\hat{\theta_{MLE}})=E(\hat(\theta_{MLE}))-\theta=-\frac{1}{2n+1}\theta$$

Find an unbiased estimator for some parameter

方法：一般来说我们一开始找到的估计量它的期望会带有这个未知参数的一部分或者除了这个未知参数以外还多了一些东西。如果一开始找到的这个估计量的期望就是未知参数，那就刚刚好，但大多数之后是有偏的——可能是多了一个系数，也可能是多了一些代数式子。那么我们就反向处理即可。

> eg1:$X^{n}$ is an iid random sample from some population with $\mu$ and $\sigma$.Find an unbiased estimator for $Var_{\theta}(\bar{X_{n}})$  
> 首先我们知道我们要估的是$\frac{\sigma^{2}}{n}$，那么我们就要找一个估计量它的期望里面能包含方差$\sigma^{2}$，所以就找到了样本方差。但是还少一个系数，所以就有  
> $$E(\frac{1}{n}S_{n}^{2})=\frac{1}{n}\sigma^{2}=\frac{\sigma^{2}}{n}$$

> eg2:$X^{n}$ is an iid random sample from some population with $\mu$ and $\sigma$.Find an unbiased estimator for $\mu^{2}$  
> 我们知道样本均值的期望是$\mu$，所以我们想到样本均值的平方可能可行。  
> $E(\bar{X_{n}}^{2})=Var(\bar{X_{n}})+[E(\bar{X_{n}})]^{2}=\frac{\sigma^{2}}{n}+\mu^{2}$,多了一个部分我们就反向处理！  
> $\because E(\frac{1}{n}S_{n}^{2})=\frac{\sigma^{2}}{n}\quad\therefore E(\bar{X_{n}}^{2}-\frac{1}{n}S_{n}^{2})=\mu^{2}$  
> $\bar{X_{n}}^{2}-\frac{1}{n}S_{n}^{2}$就是我们找的无偏估计量


**Efficiency**

对于一个未知参数，它可以有不止一个统计量，那么它当然也有可能有不止一个无偏统计量，那么对于多个无偏统计量，哪一个更好呢？

我们在考察估计量的时候，除了看其无偏性以外，还会看它的精确度(precision)。可以这样想，无偏就是这个估计量取很多次值但是它们平均来说会不会和真实的参数相等；精确度则是说这个估计量会不会大范围波动。

Definition:Relative Efficiency

Let $\hat\theta_{1}$ and $\hat\theta_{2}$ be two unbiased estimators for $\theta$.If
$$Var(\hat\theta_{2})<Var(\hat\theta_{1})$$
we say that $\hat\theta_{2}$ is more efficient than $\hat\theta_{1}$,also the relative efficiency of $\hat\theta_{2}$ with respect to $\hat\theta_{1}$ is the ratio
$$\frac{Var(\hat\theta_{1})}{Var(\hat\theta_{2})}$$

> 因为这个是2对于1的有效性，如果2对于1更加有效说明2的方差更小，所以这个ratio中分子是1的方差，分母是2的方差。

> 这里要说明一下。$Var\rightarrow\textrm{precision 准度/准确度}$，$Bias\rightarrow\textrm{accuracy 精度/精确度}$


**Mean Squared Error**

我们从unbiasedness开始比较两个estimator的好坏，然后在都是无偏的情况下时我们用efficiency来进行比较。那么进一步我们就想问一个问题：*如果一个估计量是有偏但方差小一些，另一个是无偏但方差大一些，这两个估计量哪个更优？*

$$MSE=E[(\hat\theta-\theta)^{2}]$$

> MSE的想法是：我们使用$\hat\theta$的目的是为了顾及$\theta$，所以两者当然越接近越好，那么就转变为我们怎么去度量这个接近程度。如果这样想的话，好像$E(\hat\theta-\theta)$也可以，但是问题在于它度量的是difference,它是可以正负相抵消的！因此我们进行改进就有了考虑distance的两种衡量方法  
> $$E(|\hat\theta-\theta|)\quad\textrm{or}\quad E[(\hat\theta-\theta)^{2}]$$  
> 现在我们只考虑使用平方的方法，因为从数理角度看，平方比绝对值更好处理。  
> 还要注意的一点是，这里的$\theta$并不是天然就是$\hat\theta$的期望啊!

$$MSE(\hat\theta)=E[(\hat\theta-\theta)^{2}]=E[(\hat\theta-E(\hat\theta)+E(\hat\theta)-\theta)^{2}]=E[(\hat\theta-E(\hat\theta))^{2}]+2E[(\hat\theta-E(\hat\theta))(E(\hat\theta)-\theta)]+E[(E(\hat\theta)-\theta)^{2}]$$
$$\Rightarrow MSE(\hat\theta)=Var(\hat\theta)+2(E(\hat\theta)-\theta)E[\hat\theta-E(\hat\theta)]+(E(\hat\theta)-\theta)^{2}$$
$$\therefore MSE(\hat\theta)=Var(\hat\theta)+[Bias(\hat\theta)]^{2}$$

> 可以发现，我们找到了连接*无偏性*和*有效性*去判断估计量好坏的一种方法，并且有效性其实就是当偏差为0的特例。


**Best Unbiased Estimators**

在有了MSE这个判断标准之后，如果我们想找一系列估计量中最好的那个，只要找到那个有最小均方误差的估计量即可。但是我们几乎无法一一比较每一个估计量尤其是当估计量很多的时候，因此我们做出必要的简化。我们去寻找*最优无偏估计量*

在一系列的$\hat\theta$中，称$\hat\theta_{\star}$为minimum variance unbiased estimator(MVUE) if $\hat\theta_{\star}\in\theta$ and $Var(\hat\theta_{\star})\leq Var(\hat\theta)\,for\,\hat\theta\in\theta$

**The Cramer-Rao Lower Bound**

Theorem:Let $f_{Y}(y)$ be a continuous pdf with continuous first-order and second-order derivatives.Also,suppose that the set of y values,where $f_{Y}(y)\neq0$,does not depend on $\theta$.$Y^{n}=(Y_{1},Y_{2},...,Y_{n})$ is a random sample with $f_{Y}(y,\theta)$ and let $\hat\theta=h(Y_{1},Y_{2},...,Y_{n})$ be any unbiased estimator of $\theta$.
$$Var(\hat\theta)\geq\frac{1}{nE[(\frac{\partial lnf(y,\theta)}{\partial\theta})^{2}]}=-\frac{1}{nE(\frac{\partial^{2}lnf(y,\theta)}{\partial^{2}\theta})}$$

> 首先要主义这个定理的要求，就是随机变量的取值范围不可以和未知参数有关，这里唯一的例外就是Uniform Distribution。  
> 然后这个定理是用来求一个无偏估计量的最小方差的界限的。  
> 这个定理实际上的逻辑推导过程是这样的：$Var(\hat\theta)\geq\frac{1}{Var(S(\theta,Y^{n}))}=\frac{1}{E(S^{2}(\theta,Y^{n}))}=\frac{1}{nE((\frac{\partial lnf(Y,\theta)}{\partial \theta})^{2})}=-\frac{1}{nE(\frac{\partial^{2}lnf(Y,\theta)}{\partial^{2}\theta})}$

证明的过程就不详细展开了，但是有一些定义以及知识点要说明。

1. $Score\,\,function:S(Y^{n},\theta)=\frac{\partial log\,likelihood funtion}{\partial\theta}=\sum\limits_{i=1}^{n}\frac{\partial lnf(y_{i},\theta)}{\partial\theta}$并且还有一个性质，$E[S(Y^{n},\theta)]=0$。这个score function就是我们在求MLE的时候要使其为0的function
2. Fisher Information实际上就是score function的二阶矩:$I(\theta)=E[S^{2}(Y^{n},\theta)]$。
3. 我们发现：$Var(S(Y^{n},\theta))=E(S^{2}(Y^{n},\theta))-[E(S(Y^{n}),\theta)]^{2}=E(S^{2}(Y^{n},\theta))=I(\theta)$因此我们得到了Fisher information的第一个数学意义：*用来估计MLE方程的方差*。它的直观表示就是，随着收集的数据越来越多，这个方差由于是一个independent sum的形式，也就变得越来越大也就象征着得到的信息越来越多。
4. 当log likelihood function二阶可导的情况下，一般来说(under some specific regularity conditions)很容易证明：$E[S(Y^{n},\theta)^{2}]=-E(\frac{\partial^{2}lnf(y^{n},\theta)}{\partial^{2}\theta})$，于是我们得到了Fisher information的第二个数学意义：*它是log likelihood function在参数真实值处的负二阶导数的期望*
5. Fisher information的第三个数学意义的直观含义是：*它反映了我们对参数估计的准确度，它越大，对参数估计的准确度就越高，即代表了更多的信息*
6. 从这个定理，我们知道Fisher information越大，得到的估计量的最小方差的界限就越小，也就意味着估计越准确。 
7. 一定要注意，在定理中我们使用的并不是整个random sample，而是只用了一个pdf。但是在证明的过程中，我们是从整个random sample开始推导的。

> eg1:$X^{n}=(X_{1},X_{2},X_{3},...,X_{n})\sim Possion(\lambda)$,$f(x)=e^{-\lambda}\frac{\lambda^{x}}{x!},x=0,1,2,...$。求出$\theta$的估计量，并判断是否是MVUE.  
> $L(X,\lambda)=\prod\limits_{i=1}^{n}f(x_{i},\lambda)=\prod\limits_{i=1}^{n}e^{-\lambda}\frac{\lambda^{x_{i}}}{x_{i}!}$  
> $\Rightarrow \rho(x,\lambda)=ln[\prod\limits_{i=1}^{n}e^{-\lambda}\frac{\lambda^{x_{i}}}{x_{i}!}]=\sum\limits_{i=1}^{n}e^{-\lambda}\frac{\lambda^{x_{i}}}{x_{i}!}=-n\lambda+ln\lambda\sum\limits_{i=1}^{n}x_{i}-\sum\limits_{i=1}^{n}lnx_{i}!$  
> $\Rightarrow S(X,\lambda)=-n+\frac{1}{\lambda}\sum\limits_{i=1}^{n}x_{i}=0$  
> $\therefore \hat\lambda=\bar{X_{n}}$ 且显然这是一个无偏估计量  
> 接着我们求一下无偏估计量可以取到的最小方差  
> $Var(\hat\theta)\geq \frac{1}{E[S(Y^{n},\theta)^{2}]}=-\frac{1}{E(\frac{\partial^{2}lnf(y^{n},\theta)}{\partial^{2}\theta})}=-\frac{1}{E(-\frac{1}{\lambda}\sum\limits_{i=1}^{n}X_{i})}=\frac{\lambda}{n}$  
> $\frac{\lambda}{n}=Var(\bar{X_{n}})$,$\therefore \bar{X_{n}}\textrm{is the MVUE for }\lambda$

> eg2:$X^{n}=(X_{1},X_{2},...,X_{n})\sim N(\mu,\sigma^{2})$。给出方差的估计量并判断是否是MVUE。  
> 我们可以使用样本方差，也可以使用MLE的方法来估计方差，得到的是不同的。我们先给出这两个估计量的方差。  
> $Var(S_{n}^{2})=\frac{2\sigma^{4}}{n-1}$,$Var(\hat\theta_{MLE})=Var(\frac{n-1}{n}S_{n}^{2})=\frac{2(n-1)\sigma^{4}}{n^{2}}$  
> 接下来我们来计算一下无偏估计量的最小方差，这里我们使用的方法不同于第一个例子但是是等价的。第一个例子用的是score function，而这里我们只使用一个pdf而不使用random sample。  
> $\frac{\partial^{2}lnf(x,\sigma^{2})}{\partial^{2}(\sigma^{2})}=\frac{1}{2(\sigma^{2})^{2}}-\frac{(x-\mu)^{2}}{(\sigma^{2})^{3}}$  
> $\Rightarrow I(\sigma^{2})=-nE(\frac{\partial^{2}lnf(x,\sigma^{2})}{\partial^{2}(\sigma^{2})})=\frac{n}{2\sigma^{4}}$  
> $Var(\hat\sigma^{2})\geq -\frac{1}{nE(\frac{\partial^{2}lnf(x,\sigma^{2})}{\partial^{2}(\sigma^{2})})}=\frac{2\sigma^{4}}{n}$  
> 显然我们可以看到虽然样本方差是无偏估计量，但是它并不是MVUE。并且我们还发现，MLE虽然有偏但是它的方差比无偏估计量的最小方差还要小。


**Consistency**

1. asymptotically unbiased

之前我们讨论的很多估计量都是对未知参数的有偏估计，但是其中大多数估计量的期望在n趋向于无穷的时候是无偏的，这就叫做*渐进无偏性*

2. consistency

Definition:An estimator $\hat\theta_{n}=h(W_{1},W_{2},...,W_{n})$ is said to be consistent for $\theta$ if it converges in probability to $\theta$---that is,if for all $\epsilon>0$
$$lim_{n\rightarrow\infty}P(|\hat\theta_{n}-\theta|<\epsilon)=1$$

> eg:$Y^{n}=(Y_{1},Y_{2},...,Y_{n})\sim Uniform distribution$,$f_{Y}(y,\theta)=\frac{1}{\theta},0\geq y\geq\theta$.Find the MLE;is it unbiased;is it asymptotically unbiased;is it consistent?  
> 首先MLE我们需要使用到次序统计量，这里就不详细说了。$\hat\theta_{MLE}=Y_{Max}=Y_{(n)}$  
> $E(\hat\theta_{MLE})=\frac{n}{n+1}\theta$  
> $lim_{n\rightarrow\infty}E(\hat\theta_{MLE})=\theta$，显然是渐进无偏的  
> $P(|\hat\theta_{MLE}-\theta|<\epsilon)=P(\theta-\epsilon<y_{(n)}<\theta+\epsilon,0\geq y_{(n)}\geq\theta)=P(\theta-\epsilon<y_{(n)}<\theta)=\int_{\theta-\epsilon}^{\theta}\frac{n\cdot y^{n-1}}{\theta^{n}}dy=1-(\frac{\theta-\epsilon}{\theta})^{n}$  
> $\therefore lim_{n\rightarrow\infty}P(|\hat\theta_{MLE}-\theta|<\epsilon)=1$  
> 或者我们可以使用马尔科夫不等式来得到这个结果，因为这个概率式子是可以联系到马尔科夫不等式的，这里就不展开了。

**Sufficient Estimators**

Definition[sufficient statistic]:Let $X^{n}$ be a random sample from sufficient statistic for $\theta$ if the conditional distribution of the sample $X^{n}=x^{n}$ given that the value of the statistic T(X^{n})=T(x^{n}) does not depend on $\theta$.That is 
$$f_{X^{n}|T(X^{n})}[x^{n}|T(x^{n}),\theta]=h(x^{n})\textrm{ for all possible }\theta$$



#Chapter 6 Hypothesis Testing

##Null hypothesis and alternative hypothesis

首先要弄明白“假设”是什么，在这里假设指的其实就是*两个相互冲突的针对于某个分布、针对某个参数的描述*。因此“假设检验”要做的就是我们要从两个描述中选择一个我们认为正确的。

现实中其实我们都在进行假设检验的过程。比如，我们想要知道某个汽车品牌的添加剂是否对于某型号汽车节油有功效，那么这个节省油vs不节省油就是一对相互冲突的描述。并且如果我们抽象一下，其实这个节油不节油就是想看看耗油的均值是不是比这个车型给出的初始数据要低：
$$H_{0}:\mu=\mu_{0}\quad\textrm{原假设(null hypothesis)}$$
$$v.s.\quad H_{1}:\mu<\mu_{0}\quad\textrm{备择假设(alternative hypothesis)}$$

> 一般来说，原假设是一个比较精确的等式，而备择假设则是一个不等式，比较宽泛。  
> 单边备择假设和双边备择假设：单边备择假设就是备择假设中是用小于或者大于的，而双边备择假设就是用不等于符号的。它们在检验中会稍微有一点区别。

那么下一步我们应该怎么做呢？很自然地，我们肯定想先估计一下这个均值是多少，然后再做决定。这个时候就会用到我们之前学的参数估计的知识了！可是估计完之后呢？还是很自然地我们就想，如果这个估计值比$\mu_{0}$小很多，我们就会觉得“嗯，看来是省油的”；如果这个估计值离$\mu_{0}$很近，那我们就会觉得“看来是没什么省油的效果嘛”。

那么问题就来了：这个估计值小到多少我们可以觉得它是省油的（认为备择假设正确），这个估计值在哪个范围我们可以觉得它是没有省油效果的（认为原假设正确）呢？

##Two kinds of error

现在我们先穷举一下如果我们进行了选择，将有多少种可能：

1. 在原假设正确的情况下接受原假设
2. 在原假设正确的情况下拒绝原假设
3. 在备择假设正确的情况下接受原假设
4. 在备择假设正确的情况下拒绝原假设

这四种情况中，有两种错误，即我们所要定义的*[第一类错误：拒真]*和*[第二类错误：受假]*

$$\textrm{Type I error:reject }H_{0}\textrm{ when }H_{0}\textrm{ is true}$$
$$\textrm{Type II error:fail to reject }H_{0}\textrm{ when }H_{1}\textrm{ is true}$$

既然有可能出现这样的错误，我们当然会想要避免它们。如何能够做到避免呢？这时候你可以观察这四种情况，其实它们都是*事件*。之所以说它们是事件，是因为我们在最开始先估计了均值，然后我们使用样本均值在某次取值能否小于某个值来完成*拒绝*或者*不拒绝*的选择。而样本均值是一个估计量，也就是一个随机变量，那么就带有了随机性，因此这四种情况就是*事件*了，这时候避免的方法就很显然了，通过控制犯错误的**概率**来避免错误发生。

如果扩展到任意的一次假设检验过程中，我们永远要先进行估计，所以永远存在着这样四种情况，估计量总是带有随机性的，所以这种控制犯错概率的方法就是一种一般的方法了。

我们现在知道要控制发生错误的概率，但问题是这里有两种类型的错误，我们应该怎么控制呢？是单独控制一类错误还是单独控制二类错误，还是有一起控制的方法呢？

1. 一类错误和二类错误的发生概率是相互矛盾的，如果降低一类错误的发生概率则必然会提高二类错误的发生概率。
2. 一类错误是绝对可控的，而二类错误则无法控制。之所以这么说，是因为本质上我们通过控制一类错误的概率或者二类错误的概率来做出选择，那么当我们给定某个$\alpha$，我们必须能够反解出一个特定值来作为基准。对于一类错误，它的条件是原假设成立，那么我们就可以获得未知参数的一个已知假设值，从而可以反解出这个特定值；而对于二类错误，它的条件是备择假设成立，这个假设太宽泛了，我们无法解出特定值。因此我们说一类错误可控，而二类错误无法控制。所以我们通过控制一类错误发生的概率来做出决策。
3. 因为我们首先控制一类错误，所以这就凸显除了原假设的重要性，所以我们在设立假设的时候应该把更重要的放在原假设。

**Power function**

$$P(fail\,to\,reject\,H_{0}|H_{1}\,is\,ture)=\beta$$

> 我们知道了检验是通过控制一类错误的发生概率来进行的，但是二类错误我们也不能忽略。因此我们也要来谈一谈二类错误。一个重要的点是，我们控制一类错误来找到critical value，二类错误是基于这个critical value来计算的。

$$power\,function=1-\beta$$
如果我们拿均值检定作为例子的话，容易发现：
$$power function=f(\mu_{1}),\alpha为外生变量$$

> power function有两个作用，首先它能够展示在不同的$H_{1}$的情况下的二类错误发生的概率，其次它还有一个很重要的作用就是对不同的检定统计量(估计量)进行比较。假设我们有两个检定统计量它们都可以做检定，那么我们通过控制一类错误的发生概率，可以得到critical value，但是这两个检定统计量在相同的$\alpha$下，二类错误发生的概率是不同的。我们当然希望一类、二类错误的发生概率都较低的，因此我们会选择这两个检定统计量中power function更小的。


##几种检验的方法

**Critical value**

In practice,in order to find an appropriate cutoff value so that we can make a choice,we control the probability of making Type I error under some *prespecified* level $\alpha$:
$$P(reject\,\,H_{0}|H_{0}\,is\,true)=\alpha$$
$\alpha$ is called the level of significance of the test.

> 这里的$\alpha$就是我们在上一节说到的要控制的犯错误的概率，如果我们设置这个$\alpha$越小说明我们越不能容忍一类错误的发生，那么相应的二类错误的发生概率就会增加。  
> 不同的$\alpha$将会反解得到不同的critical value

导致发生一类错误的方向的一系列值就是critical region，而那个交界点就是critical value。当我们的估计量取值落入critical region的时候我们就要拒绝原假设。

> 逻辑：我们控制一类错误在一个很小的概率下，也就是说估计量取这一部分的值的概率是很低的。但是当实际情况中确实发生了，它就相当于是小概率事件，或者说“事出反常必有妖”。这种时候我们不认为说是这个估计量真的取到了这样一个极端值，而认为实际上这个估计量不服从这个分布才出现了这样的情况，也就是说原假设是错误的。

**P-value**

$$P-value=\alpha_{0}=P(Z\,is\,as\,extrem\,as\,or\,more\,extrem\, than\,z_{obs}|H_{0}\,is\,true)$$

这种方法的思路和上一个其实是一样的，只不过它更加直接。这种方法直接去计算在原假设成立的情况下估计量的观测值发生的极端性有多高，然后拿它和$\alpha$进行比较，如果比$\alpha$还要小，那就等同于发生了小概率事件，那么就认为原假设是错误的。

> 在实际操作中，这种检定方法比计算出critical value更加方便和快速，所以我们一般都是通过计算p-value来进行决策。

> 不论是第一种还是第二种方法，它都是一种反证法逻辑的体现。当出现某种极端情况时，我们认为是由于一个东西错误了导致的——原假设错误

**Confidence Interval**

为什么我们要加上这么一个东西呢？首先我必须说的是，使用自信区间来做检定并不是一个好的选择，因为在我看来它并没有直接地表现出控制一类概率的过程，但是从逻辑上看，它使用了前面两种方法都使用到的“反证”的思想。

首先，自信区间的定义使得我们能够控制说真实的未知参数以某个概率落入这个区间内。那么当我们进行一次取值，得到了一个区间时我们认为真实参数几乎一定落在这个区间，这时候如果原假设并没有进入这个区间，我们认为出现了极端情况，有东西出现错误了，也就是原假设错误。



##Generalized likelihood Ratio Test(GLRT)

我们在讲这个test之前先给出假设检验的一个步骤总结：

1. parameter of interest and the associated hpyothesis testing.
2. Test statistic and its distribution under $H_{0}$ is true
3. 
4. 
5. 

> 我之所以只写前两个是因为后三个只涉及到计算，并不是困难的地方。假设检验中最困难的是前两个步骤，但是我们使用的例子一直是均值，所以感觉不出难度。实际上，如果给出一个实际问题，那么我们首先就要找到我们所关心的参数、并做出适当的假设，然后我们必须得到在原假设正确的情况下检定统计量的分布！这十分重要！

所以我们现在讨论一个更一般的情况，即$\theta=\theta_{0}$，它既不是均值也不是什么p，而只是一个一般化的参数。在检定均值的时候，我们得出检定统计量的过程很自然，首先我们用样本均值估计了均值，然后直接数理化地翻译了reject $H_{0}$，也就是使用不等式，接着因为有原假设正确的条件，我们就通过CLT得到了标准正态分布，那么这个检定统计量就得到了。但是如果换成一个一般的参数，我们只能使用MLE或者MME来估计它，接着我们也直接的用不等式的方法，可是因为CLT是只针对样本均值的，这时候我们就构造不出检定统计量。

所以我们更换一种方法。

* 我们使用MLE作为估计量。
* 当$H_{0}$是正确的，也就是说$\theta=\theta_{0}$,这时候我们认为$L(\theta)_{max}=L(\theta_{0})=L(\hat\theta_{MLE})$。这里要注意的是，这不是严谨的写法，毕竟估计量是一个随机变量，而$\theta_{0}$是一个值。但是我们所表示的意思是，它们俩带进去得到的likelihood应该差不多。
* 当$H_{1}$是正确的，我们就不知道$\theta$是什么，但是至少$\theta\neq\theta_{0}$,那么这个时候我们认为$L(\theta)_{max}=L(\hat\theta_{MLE})>L(\theta_{0})$,同样的这个不是一个严谨的写法，但是意思就是它们俩带进去得到的likelihood会有一定差距。
* 令$\lambda=\frac{L(\theta_{0})}{L(\hat\theta_{MLE})}$,则有$\lambda\in(0,1]$。当$\lambda$在1以及小于1一些的数值波动时，我们认为$H_{0}$是正确的，而当$\lambda$比1小比较多的时候我们认为$H_{0}$不正确。
* 我们这时候直接“翻译”reject $H_{0}$为$0<\lambda<\lambda^{\star}$，至此我们就只差找到$\lambda$在原假设正确时的分布了。
* Theorem[Asymptotic Distribution of the GLRT]:For testing $H_{0}:\theta=\theta_{0}$ versus $H_{1}:\theta\neq\theta_{0}$.Suppose $X_{1},X_{2},...,X_{n}$ are iid $f(x,\theta)$,under some regularity conditions,we have,under $H_{0}$ is true,as $n\rightarrow\infty$,$$-2ln\lambda\xrightarrow{d}X_{1}^{2}$$  
* 还要补充的一点是，上面我们说的是$\theta=\theta_{0}$，但是在后面我们会发现它不仅仅只是单样本的情况，所以我们可能要把$L(\theta_{0})$换成$L(\hat{\theta}_{MLE}|H_{0})$


> eg1:$Y^{n}=(Y_{1},Y_{2},...,Y_{n})$是随机样本服从uniform distribution over the interval $[0,\theta]$,$\theta$为未知参数。  
> $H_{0}:\theta=\theta_{0}$,$H_{1}:\theta<\theta_{0}$  
> 我们首先得到$\lambda$的表达式：$L(\theta)=(\frac{1}{\theta})^{n}$,$L(\theta_{0})=(\frac{1}{\theta_{0}})^{n}$,$L(\hat\theta_{MLE})=(\frac{1}{Y_{max}})^{n}$,$$\lambda=\frac{L(\theta_{0})}{L(\hat\theta_{MLE})}=(\frac{Y_{max}}{\theta_{0}})^{n}$$  
> 这时候我们发现，我们不需要使用渐进理论就能得到$\lambda$的分布，这不就是我们想要的吗！所以我们直接开始控制一类错误。  
> $P(reject\,H_{0}|H_{0}\,is\,true)=\alpha$  
> $\Rightarrow P(0<\lambda<\lambda^{\star}|H_{0}\,is\,true)=\alpha$  
> $\Rightarrow P(Y_{max}<\theta_{0}\sqrt[n]{\lambda^{\star}}|H_{0}\,is\,true)=\alpha$  
> $\Rightarrow \int_{0}^{\theta_{0}}\sqrt[n]{\lambda^{\star}}\frac{n\cdot y^{n-1}}{\theta_{0}^{n}}dy=\alpha$  
> 得到最后的$\lambda^{\star}=\alpha$，之后就可以根据观测值计算出$lambda_{obs}$，就可以进行判断了

> eg2:Let $X^{n}=(X_{1},X_{2},...,X_{n})$ be a random sample from a $N(\mu,\sigma^{2})$ populatioN assuming $\sigma^{2}$ is known.Find the GLRT for the testing $H_{0}:\mu=\mu_{0}$ versus $H_{1}:\mu\neq\mu_{0}$  
> 要注意这是一个双边备择假设。我们还是从$\lambda$找起。  
> $\lambda=\frac{L(\theta_{0})}{L(\hat\theta_{MLE})}=\frac{L(\mu_{0})}{L(\bar{X_{n}})}=exp\{-\frac{n(\bar{X_{n}}-\mu_{0})^{2}}{2\sigma^{2}}\}$  
> $\Rightarrow P(0<\lambda<\lambda^{\star}|H_{0}\,is\,true)=\alpha$  
> $\Rightarrow P(exp\{-\frac{n(\bar{X_{n}}-\mu_{0})}{2\sigma^{2}}\}\leq\lambda^{\star})=P((\frac{\bar{X_{n}}-\mu_{0}}{\sigma/\sqrt{n}})^{2}\geq -2ln\lambda^{\star})=\alpha$  
> $\Leftrightarrow P(\frac{|\bar{X_{n}}-\mu_{0}|}{\sigma/\sqrt{n}}\geq C^{\star}) =\frac{\alpha}{2}$  
> 所以我们会发现其实Z-test也是一个GLRT


#Chapter 7 Inference Based on the Normal Distribution

这一章首先是对上一章的扩展，另外就是我们明确是在正态分布的分布假设下进行的。

1. 当方差未知时，如何进行均值检定。
2. 对方差进行检定。

##T test

**Definition**:Let $U\sim N(0,1)$,$V\sim X_{v}^{2}$,and U and V are independent.Then the random variable
$$T=\frac{U}{\sqrt{\frac{V}{v}}}\sim \frac{N(0,1)}{\sqrt{\frac{X_{v}^{2}}{v}}}$$
follows a *Student's t distribution with v degrees of freedom*,denoted as
$$T\sim t_{v}$$

* $f_{T}(t)=\frac{\tau(\frac{v+1}{2})}{\tau(\frac{v}{2})}\cdot\frac{1}{(v\pi)^{\frac{1}{2}}}\cdot\frac{1}{(1+\frac{t^{2}}{v})^{\frac{v+1}{2}}},-\infty<t<\infty$  
* t分布对称分布
* t distribution has a heavier distribution tail than N(0,1)  
* Only the first v-1 moments exist
* 当v逐渐增长并趋向于无穷时，$t_{v}\rightarrow N(0,1)$  

**Theorem**:Let $(Y_{1},Y_{2},...,Y_{n})$ be an IID random sample from a $N(\mu,\sigma^{2})$ distribution.Then for all $n>1$,the standardized sample mean
$$\frac{\bar{Y_{n}}-\mu}{S_{n}/\sqrt{n}}=\frac{\frac{\bar{Y_{n}}-\mu}{\sigma/\sqrt{n}}}{\sqrt{\frac{(n-1)S_{n}^{2}}{(n-1)\sigma^{2}}}}\sim\frac{N(0,1)}{\sqrt{\frac{X_{n-1}^{2}}{n-1}}}\sim t_{n-1}$$
where $t_{n-1}$ is the Student t-distribution with n-1 degrees of freedom and the sample variance $S_{n}^{2}=\frac{1}{n}\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2}$

> 这里需要注意，为什么我们需要正态分布？因为t分布的构造要求分子部分与分母部分是独立的，在正态分布假设下我们证明过样本均值和样本方差是独立的。  
> 其实和方差已知没有很大的改变。也就是把未知的方差换成样本方差，另外就是自信区间的估计，也是换成样本方差即可。不过当自由度大于30或者是大于50就已经可以用标准正态来代替了。  
> 自信区间：$[\bar{Y_{n}}-t_{\frac{\alpha}{2},n-1}\frac{S_{n}}{\sqrt{n}},\bar{Y_{n}}+t_{\frac{\alpha}{2},n-1}\frac{S_{n}}{\sqrt{n}}]$


**Normality Assumption**

如果取消了正态分布的假设，还能进行检定吗？答案是肯定的。

稳健性：一个理论中改变某个假设，或是改变一些参数值时，对于得出或是可以使用的情况不会有太大的偏离（对假设的依赖度低）

T-test具有稳健性，只要样本不要太少或者分布不要太偏就可以使用：我们使用Slutsky's Theorem即可。

**GLRT**

我们可以证明T-test也是一个GLRT

> proof:$(Y_{1},Y_{2},...,Y_{n})\sim N(\mu,\sigma^{2})$, $H_{0}:\mu=\mu_{0}$ v.s. $H_{1}:\mu\neq\mu_{0}$  
> 这里就会发现，还有一个参数需要估计，所以就必须分成两种情况来估计。  
> 我们先得到MLE的式子，

$$\left\{
\begin{array}{1}
\hat{\mu}=\frac{1}{n}\sum\limits_{i=1}^{n}y_{i}\\
\hat{\sigma^{2}}=\frac{1}{n}\sum\limits_{i=1}^{n}(y_{i}-\mu)^{2}\\
\end{array}
\right.$$

> 当原假设正确时，$\hat{\mu}=\mu_{0},\widetilde{\sigma^{2}}=\frac{1}{n}\sum\limits_{i=1}^{n}(y_{i}-\mu_{0})^{2}$，所以我们得到

$$L(\mu_{0},\widetilde{\sigma^{2}})=(2\pi\widetilde{\sigma^{2}})^{-\frac{n}{2}}exp\{-\frac{1}{2}\cdot\frac{\sum\limits_{i=1}^{n}(y_{i}-\mu_{0})^{2}}{\frac{1}{n}\sum\limits_{i=1}^{n}(y_{i}-\mu_{0})^{2}}\}$$  

> 当备择假设正确时，$\hat{\mu}=\bar{Y_{n}},\hat{\sigma^{2}}=\frac{1}{n}\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2}$,所以我们得到

$$L(\hat{\mu},\hat{\sigma^{2}})=(2\pi\hat{\sigma^{2}})^{-\frac{n}{2}}exp\{-\frac{1}{2}\frac{\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2}}{\frac{1}{n}\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2}}\}$$  

> $\therefore \lambda=\frac{L(\mu_{0},\widetilde{\sigma^{2}})}{L(\hat{\mu},\hat{\sigma^{2}})}=(\frac{\widetilde{\sigma^{2}}}{\hat{\sigma^{2}}})^{-\frac{n}{2}}=(\frac{\sum\limits_{i=1}^{n}(Y_{i}-\mu_{0})^{2}}{\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2}})^{-\frac{n}{2}}=[1+\frac{(\bar{Y_{n}}-\mu_{0})^{2}}{\frac{\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2}}{n}}\cdot\frac{1}{n-1}]^{-\frac{n}{2}}=[1+\frac{T^{2}}{n-1}]^{-\frac{n}{2}}$  
> 接下来就是“翻译”一下，然后就可以反解出cutoff value了。


##Chi-square test

我们介绍了关于均值检定的Z-test和T-test，现在我们要对正态分布下的$\sigma^{2}$进行假设检验。

首先，我们当然是找到一个估计量来估计方差：样本方差。接着，我们仍然通过控制一类错误来做出选择，那么问题就来了，怎么能够“翻译”好“拒绝原假设”这句话呢？我们先会想到使用均值检定时使用的直接比大小，但是在均值检定中是构造了一个相减的式子，这里显然不行！但是除了相减，我们还可以做除法，并且这时候你要记起来在正态分布假设下，有一个关于样本方差的分布理论。

$$\frac{(n-1)S_{n}^{2}}{\sigma^{2}}\sim\chi_{n-1}^{2}$$

**GLRT**

我们现在同样可以证明，它也是一个GLRT

> proof:$(Y_{1},Y_{2},...,Y_{n})\sim N(\mu,\sigma^{2})$,$H_{0}:\sigma^{2}=\sigma_{0}^{2}$ v.s. $H_{1}:\sigma^{2}\neq\sigma_{0}^{2}$  
> 我们同样使用MLE先得到参数的估计量。  

$$\left\{
\begin{array}{1}
\hat{\mu}=\frac{1}{n}\sum\limits_{i=1}^{n}y_{i}\\
\hat{\sigma^{2}}=\frac{1}{n}\sum\limits_{i=1}^{n}(y_{i}-\mu)^{2}\\
\end{array}
\right.$$

> 当原假设正确的时候，$\sigma^{2}=\sigma_{0}^{2},\widetilde{\mu}=\bar{Y_{n}}$,所以我们得到

$$L(\widetilde{\mu},\sigma^{2})=L(\widetilde{\mu},\sigma_{0}^{2})=(2\pi\sigma_{0}^{2})^{-\frac{n}{2}}exp\{-\frac{\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2}}{2\sigma_{0}^{2}}\}$$

> 当备择假设正确的时候，$\hat{\sigma^{2}}=\frac{1}{n}\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2},\hat{\mu}=\bar{Y_{n}}$,所以我们得到

$$L(\hat{\mu},\hat{\sigma^{2}})=(\frac{2\pi}{n}\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2})^{-\frac{n}{2}}exp\{-\frac{n}{2}\}$$

> $\therefore \lambda=\frac{L(\widetilde{\mu},\sigma_{0}^{2})}{L(\hat{\mu},\hat{\sigma^{2}})}=(\frac{\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2}}{n\sigma_{0}^{2}})^{\frac{n}{2}}exp[-\frac{\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2}}{2\sigma_{0}^{2}}]exp(-\frac{n}{2})$  
> 因为我们要证明chi-square test实际上是GLRT,所以我们要凑出分布来。  
> 令$T=\frac{\sum\limits_{i=1}^{n}(Y_{i}-\bar{Y_{n}})^{2}}{\sigma^{2}}$  
> $\Rightarrow \lambda=(\frac{T}{n})^{\frac{n}{2}}e^{-\frac{T}{2}}e^{\frac{n}{2}}$  
> 然后其实就只是求值的过程了，因为我们构造的T是一个已知分布。

**Confidence Interval**

$$P\{\chi_{\frac{\alpha}{2},n-1}^{2}\leq\frac{(n-1)S_{n}^{2}}{\sigma^{2}}\leq\chi_{1-\frac{\alpha}{2},n-1}^{2}\}=1-\alpha$$
$$\textrm{Confidence interval:}[\frac{(n-1)S_{n}^{2}}{\chi_{1-\frac{\alpha}{2},n-1}^{2}},\frac{(n-1)S_{n}^{2}}{\chi_{\frac{\alpha}{2},n-1}^{2}}]$$


#Chapter 9 Two-sample Inferences(under normal distribution)

所谓两样本，就是说我们的假设不是只涉及一个样本，前一章我们不论是均值检定或者是方差检定都是针对一个样本来说的。现在我们针对两样本，因此我们的假设也就相应的发生比较大的变化。

##Hypothesis Testing on Two population Means

$$H_{0}:\mu_{1}=\mu_{2}\quad v.s.\quad H_{1}:\mu_{1}\neq\mu_{2}$$
$$H_{0}:\mu_{1}=\mu_{2}\quad v.s.\quad H_{1}:\mu_{1}>\mu_{2}$$
$$H_{0}:\mu_{1}=\mu_{2}\quad v.s.\quad H_{1}:\mu_{1}<\mu_{2}$$

两样本均值检定的假设就是这三种，但是带来的检定过程中大差别并不大。问题是这个时候我们要控制一类错误的话，我们应该如果翻译“reject H0”呢？稍加观察我们发现，只要把参数移到一侧那么其实是相同的：$H_{0}:\mu_{1}-\mu_{2}=0\quad v.s.\quad H_{1}:\mu_{1}-\mu_{2}\neq 0$。

解决了这个问题，我们还有两个小问题，一个就是关于方差，正如我们在上一章所遇到的一样；另一个就是针对两个样本之间的关系，是否要进行不同的处理。接下来我们就针对这两个小问题分类讨论，我们以左单边备择假设为例。

**两样本独立且方差均已知**

我们还是一样的思路：先估计，估计之后考虑怎么翻译“reject H0”，之后就正常了。我们做一个展示，在之后的情况就不再详细解释。

$$P(reject \,\,H_{0}|H_{0}\,is\,true)=P(\bar{X_{1}}-\bar{X_{2}}<\lambda^{\star}|H_{0}\,is\,true)=P(\frac{(\bar{X_{1}}-\bar{X_{2}})-(\mu_{1}-\mu_{2})}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}}<\frac{\lambda^{\star}-(\mu_{1}-\mu_{2})}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}}|H_{0}\,is\,true)=\alpha$$
$$\Rightarrow P(Z:Z^{\star}<\frac{\lambda^{\star}-(\mu_{1}-\mu_{2})}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}}|H_{0}\,is\,true)=P(Z:Z^{\star}<\frac{\lambda^{\star}}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}})=\alpha$$
$$\therefore\quad-Z_{\alpha}=\frac{\lambda^{\star}}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{2}^{2}}{n_{2}}}}$$

> 这里是因为样本是正态分布且两个样本独立，因此我们可以得到两个样本均值的差也服从正态分布。

**两样本独立但方差未知，但方差相同**

方差未知，我们和单样本方差未知时的解决方法一样，都是用样本方差去替代并构造t分布。但是现在的问题是，我们有两个样本方差我们应该如何使用呢？

$$\frac{(n_{1}-1)S_{1}^{2}}{\sigma^{2}}+\frac{(n_{2}-1)S_{2}^{2}}{\sigma^{2}}=\frac{(n_{1}-1)S_{1}^{2}+(n_{2}-1)S_{2}^{2}}{\sigma^{2}}\sim\chi_{n_{1}+n_{2}-2}^{2}$$
$$令\quad S_{p}^{2}=\frac{(n_{1}-1)S_{1}^{2}+(n_{2}-1)S_{2}^{2}}{n_{1}+n_{2}-2}$$

我们会使用加权平均的方法得到一个pooled sample variance。那么为了凑出一个t分布，我们就可以用和单样本时相同的方法：

$$\frac{\frac{(\bar{X_{1}}-\bar{X_{2}})-(\mu_{1}-\mu_{2})}{\sigma\sqrt{1/n_{1}+1/n_{2}}}}{\sqrt{\frac{S_{p}^{2}}{\sigma^{2}}}}=\frac{(\bar{X_{1}}-\bar{X_{2}})-(\mu_{1}-\mu_{2})}{S_{p}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}}\sim t_{n_{1}+n_{2}-2}$$

所以分布我们找到了，对于如何翻译“reject H0”的问题，其实是类似的我们就不详细说了。但是有一个问题就是说，$S_{p}$是一个随机变量，它也出现在了反解的过程中，这应该如何理解呢？简单地理解为观测值当然是可以解的，但是这样说得通吗？因为


> 我们现在用GLRT的方法证明一下这种情况实际上也是一种GLRT。  
> 回忆一下GLRT的方法，我们实际上是将$L(\hat{\theta}_{MLE})$作为标准，然后将原假设域下求出的似然函数的最大值来和它比较。  
> $L(\mu_{x},\mu_{y},\sigma^{2})=\prod\limits_{i=1}^{n}f(x_{i})\prod\limits_{i=1}^{n}f(y_{i})=(2\pi\sigma^{2})^{-\frac{n+m}{2}}exp\{-\frac{1}{2\sigma^{2}}[\sum\limits_{i=1}^{n}(x_{i}-\mu_{x})^{2}+\sum\limits_{i=1}^{m}(y_{i}-\mu_{y})^{2}]\}$  
> 当原假设成立时，$\mu_{x}=\mu_{y}=\mu$,$L(\mu_{x},\mu_{y},\sigma^{2})=L(\mu,\sigma^{2})=(2\pi\sigma^{2})^{-\frac{n+m}{2}}exp\{-\frac{1}{2\sigma^{2}}[\sum\limits_{i=1}^{n}(x_{i}-\mu)^{2}+\sum\limits_{i=1}^{m}(y_{i}-\mu)^{2}]\}$   
> 我们可以解得$$\widetilde{\mu}=\frac{\sum\limits_{i=1}^{n}x_{i}+\sum\limits_{i=1}^{n}y_{i}}{n+m},\widetilde{\sigma^{2}}=\frac{1}{n+m}[\sum\limits_{i=1}^{n}(x_{i}-\widetilde{\mu})^{2}+\sum\limits_{i=1}^{m}(y_{i}-\widetilde{\mu})^{2}]$$  
> 当备择假设成立时，我们求$L(\hat{\theta}_{MLE})$,这时候有三个未知参数。  
> 我们可以解得$$\hat{\mu}_{x}=\bar{X_{n}},\hat{\mu}_{y}=\bar{Y_{n}},\hat{\sigma^{2}}=\frac{1}{n+m}[\sum\limits_{i=1}^{n}(x_{i}-\hat{\mu}_{x})^{2}+\sum\limits_{i=1}^{m}(y_{i}-\hat{\mu}_{y})^{2}]$$  
> $$\lambda=\frac{L(\widetilde{\mu},\widetilde{\sigma^{2}})}{L(\hat{\mu_{x}},\hat{\mu_{y}},\hat{\sigma^{2}})}=(\frac{\hat{\sigma^{2}}}{\widetilde{\sigma^{2}}})^{\frac{n+m}{2}}=[\frac{\sum\limits_{i=1}^{n}(x_{i}-\bar{X_{n}})^{2}+\sum\limits_{i=1}^{m}(y_{i}-\bar{Y_{n}})^{2}}{\sum\limits_{i=1}^{n}(x_{i}-\frac{n\bar{X_{n}}+m\bar{Y_{m}}}{n+m})^{2}+\sum\limits_{i=1}^{m}(y_{i}-\frac{n\bar{X_{n}}+m\bar{Y_{m}}}{n+m})^{2}}]^{\frac{n+m}{2}}$$  
> 但是我们要凑出t分布才可以，所以我们对$\lambda$继续进行变形，得到$$\lambda=(\frac{n+m-2}{(n+m-2)+T^{2}})^{\frac{n+m}{2}}$$  
> 我们进行决策的标准是找到一个$\lambda^{\star}$比1小比较多，并且我们发现$\lambda$随着$T^{2}$递减，所以就得出当$T^{2}$大于某个值就拒绝$H_{0}$  
> 剩下的就是控制一类错误了，没有什么好说的。但是需要注意的是，GLRT应该只能适用于双边检定，不然就有问题。


**两样本独立但方差未知，且方差互不相同**

我们同样是用样本方差去替代方差，但是这时候我们找不到它的分布。

$$\frac{(\bar{X_{1}}-\bar{X_{2}})-(\mu_{1}-\mu_{2})}{\sqrt{\frac{S_{1}^{2}}{n_{1}}+\frac{S_{2}^{2}}{n_{2}}}}\sim ?$$

*Welch-Satterthuaites Approximation*

一种渐近的方法，$X_{1},X_{2},...,X_{n}$ be a random sample of size n from a normal distribution with mean $\mu_{x}$ and standard deviation $\sigma_{x}$ and let $Y_{1},Y_{2},...,Y_{n}$ be a random sample of size m from a normal distribution with mean $\mu_{y}$ and $\sigma_{y}$.Two random samples are independent.

$$T=\frac{\bar{X}-\bar{Y}-(\mu_{x}-\mu_{y})}{\sqrt{\frac{S_{1}^{2}}{n_{1}}+\frac{S_{2}^{2}}{n_{2}}}}$$
Then T has approximately a Student t distribution with v degrees of freedom,where v is the nearest integer of the following expression

$$\frac{(S_{x}^{2}/n+S_{y}^{2}/m)^{2}}{(S_{x}^{2}/n)^{2}/(n-1)+(S_{y}/m)^{2}/(m-1)}$$

通过这一个渐近理论，我们就找到了在原假设成立下的test statistics和对应的分布。




**两样本匹配且方差未知**

我们这里的匹配针对的是“实验前”“实验后”这种单个观测体的两次观测的情况，因此两个样本组高度相关。我们的做法是将其转化为单样本问题

$$D=X-Y,D\sim N(\mu_{d},\sigma^{2}_{d})$$

从而我们的假设检验就变为，

$$H_{0}:\mu_{d}=0\quad v.s.\quad H_{1}:\mu_{d}\neq 0\quad\textrm{方差未知,正态分布}$$



##Hypothesis testing on Two population variance

$$H_{0}:\sigma_{X}^{2}=\sigma_{Y}^{2}\quad v.s.\quad H_{1}:\sigma_{X}^{2}\neq\sigma_{Y}^{2}$$
$$H_{0}:\sigma_{X}^{2}=\sigma_{Y}^{2}\quad v.s.\quad H_{1}:\sigma_{X}^{2}<\sigma_{Y}^{2}$$
$$H_{0}:\sigma_{X}^{2}=\sigma_{Y}^{2}\quad v.s.\quad H_{1}:\sigma_{X}^{2}>\sigma_{Y}^{2}$$

同样的思路，我们先寻找估计量进行估计。自然地我们会选择样本方差作为估计量，但是接下来我们应该怎么翻译“reject H0”呢？是不是还能够像两样本均值检定一样使用相减的方法来翻译呢？

我们一定要借助一些已知的分布，当提到样本方差我们就会想到卡方分布（正态分布假设下）。所以如果我们直接转换成$S_{X}^{2}-S_{Y}^{2}$的话，好像没办法构造出什么分布。

*F distribution*

Let U and V be two independent Chi-square random Variables with p and q degrees of freedom respectively.Then the R.V.
$$F=\frac{\frac{U}{p}}{\frac{V}{q}}$$
follows a F distribution with p and q degrees of freedom,denoted by
$$F_{p,q}$$

* If $X\sim F_{p,q},then X^{-1}\sim F_{q,p}$
* If $X\sim t_{q},then X^{2}\sim F_{1,q}$
* If $q\rightarrow\infty$,then $p\cdot F_{p,q}\rightarrow\chi_{p}^{2}$


现在我们就可以进行翻译了(左单边为例)，

$$P(reject\,H_{0}|H_{0}\,is\,true)=P(\frac{S_{X}^{2}}{S_{Y}^{2}}<\lambda^{\star}|H_{0}\,is\,true)=P(\frac{\frac{(n-1)S_{X}^{2}}{\sigma_{X}^{2}}}{\frac{(m-1)S_{Y}^{2}}{\sigma_{Y}^{2}}}<\frac{n-1}{m-1}\cdot\frac{\sigma_{Y}^{2}}{\sigma_{X}^{2}}\cdot\lambda^{\star}|H_{0}\,is\,true)$$
$$\Rightarrow P(F:F^{\star}<\frac{n-1}{m-1}\cdot\frac{\sigma_{Y}^{2}}{\sigma_{X}^{2}}\cdot\lambda^{\star}|H_{0}\,is\,true)=P(F:F^{\star}<\frac{n-1}{m-1}\cdot\lambda^{\star})=\alpha$$
$$\therefore F_{n-1,m-1,\alpha}=\frac{n-1}{m-1}\cdot\lambda^{\star}$$


这样就可以反解我们需要的critical value了，对于p-value而言也差不多。


##本章结尾

我们不介绍二项分布的概率p有关检定，因为它也是用样本均值，本质上和均值检定时一样的。

两样本的自信区间我们也不写了，重点就是枢轴量找到就好了。


> 在这一章的最后我想要提的是，我们做检定的核心是找到一个分布，同时在一类错误的计算式子中能够反解出那个“决策标准”。  
> 举一个很简单的例子，就像两样本方差检定时，我们当然也可以这样翻译“reject H0”:$$P(S_{X}^{2}-S_{Y}^{2}<\lambda^{\star}|H_{0}\,is\,true)$$
> 但是这里的问题是，我们得不到一个已知分布，那我们就无法反解出$\lambda^{\star}$  

* 运用histogram(直方图),去画出大概的pdf
* 运用asymptotic theory(渐近理论)
* 运用bootstrap(自助法)

> 除了现在给出的各种构造已知分布的方法，我们还提供上述三种方法去近似的找到分布。



#Chapter 10 Goodness of Fit Tests












